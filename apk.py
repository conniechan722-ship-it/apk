#!/usr/bin/env python3
"""
APKå¤šç»´åº¦åˆ†æç³»ç»Ÿ - åŸºäºå¤šæ™ºèƒ½ä½“åä½œçš„æ·±åº¦APKåˆ†ææ¡†æ¶
ä½¿ç”¨Ollamaæ¨¡å‹è¿›è¡Œå…¨æ–¹ä½APKå®‰å…¨ä¸ç»“æ„åˆ†æ
"""

import argparse
import json
import os
import sys
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncio
from pathlib import Path
import shutil
import re
import subprocess
import zipfile
import tempfile
import random
import traceback
import sqlite3
from tqdm import tqdm
import aiohttp
import requests


# å¸¸é‡å®šä¹‰
DECOMPILE_TIMEOUT = 300  # åç¼–è¯‘è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
PACKER_CONFIDENCE_MULTIPLIER = 30  # åŠ å£³æ£€æµ‹ç½®ä¿¡åº¦ä¹˜æ•°
MAX_SCAN_FILES = 50  # ä»£ç æ‰«ææœ€å¤§æ–‡ä»¶æ•°


def find_ollama_path() -> str:
    """æŸ¥æ‰¾ Ollama å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„"""
    ollama_path = shutil.which('ollama')
    if ollama_path:
        print(f"âœ“ æ‰¾åˆ° Ollama: {ollama_path}")
        return ollama_path
   
    if sys.platform == 'win32':
        username = os.getenv('USERNAME', 'User')
        possible_paths = [
            r'd:\Ollama\ollama.exe',
            r'e:\Ollama\ollama.exe',
            r'f:\Ollama\ollama.exe',
            rf'C:\Users\{username}\AppData\Local\Programs\Ollama\ollama.exe',
            rf'D:\Users\{username}\AppData\Local\Programs\Ollama\ollama.exe',
            rf'C:\Users\{username}\AppData\Local\Ollama\ollama.exe',
            r'C:\Program Files\Ollama\ollama.exe',
            r'D:\Program Files\Ollama\ollama.exe',
            r'C:\Program Files (x86)\Ollama\ollama.exe',
            r'C:\ProgramData\Ollama\ollama.exe',
            r'C:\Ollama\ollama.exe',
        ]
       
        for path in possible_paths:
            if os.path.exists(path):
                print(f"âœ“ æ‰¾åˆ° Ollama: {path}")
                return path
   
    print("âš ï¸  æœªæ‰¾åˆ° Ollamaï¼Œè¯·ç¡®ä¿å·²å®‰è£…: https://ollama.ai")
    return 'ollama'


OLLAMA_PATH = find_ollama_path()
DEFAULT_MODEL = 'qwen2.5:32b'


def find_decompiler_tools() -> Dict[str, str]:
    """æŸ¥æ‰¾åç¼–è¯‘å·¥å…·"""
    tools = {}
    # æŸ¥æ‰¾ jadx
    jadx_path = shutil.which('jadx')
    if jadx_path:
        tools['jadx'] = jadx_path
        print(f"âœ“ æ‰¾åˆ° jadx: {jadx_path}")
    # æŸ¥æ‰¾ apktool
    apktool_path = shutil.which('apktool')
    if apktool_path:
        tools['apktool'] = apktool_path
        print(f"âœ“ æ‰¾åˆ° apktool: {apktool_path}")
    
    if not tools:
        print("âš ï¸  æœªæ‰¾åˆ°åç¼–è¯‘å·¥å…· (jadx/apktool)")
    
    return tools


def get_ollama_models(base_url: str = "http://127.0.0.1:11434") -> List[str]:
    """ä»Ollama APIè·å–å·²å®‰è£…çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        if response.status_code == 200:
            data = response.json()
            models = [model["name"] for model in data.get("models", [])]
            return models
        else:
            print(f"âš ï¸ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: HTTP {response.status_code}")
    except requests.exceptions.ConnectionError:
        print(f"âš ï¸ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ ({base_url})")
        print(f"    è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ: ollama serve")
    except Exception as e:
        print(f"âš ï¸ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
    return []


class APKExtractor:
    """APKä¿¡æ¯æå–å™¨"""
   
    def __init__(self, apk_path: str, enable_decompile: bool = False, output_dir: str = None, analyze_db: bool = False):
        self.apk_path = apk_path
        self.temp_dir = tempfile.mkdtemp()
        self.extracted_info = {}
        self.enable_decompile = enable_decompile
        self.output_dir = output_dir or tempfile.mkdtemp()
        self.decompile_dir = None
        self.decompiler_tools = find_decompiler_tools() if enable_decompile else {}
        self.analyze_db = analyze_db
       
    def extract_basic_structure(self) -> Dict[str, Any]:
        """æå–APKåŸºæœ¬ç»“æ„"""
        print("\nğŸ“¦ æ­£åœ¨æå–APKåŸºæœ¬ç»“æ„...")
       
        structure = {
            "file_list": [],
            "file_sizes": {},
            "total_size": 0,
            "dex_files": [],
            "so_files": [],
            "resource_files": [],
            "manifest_found": False,
            "certificate_found": False
        }
       
        try:
            with zipfile.ZipFile(self.apk_path, 'r') as zip_ref:
                structure["file_list"] = zip_ref.namelist()
                structure["total_size"] = os.path.getsize(self.apk_path)
               
                for file_info in zip_ref.infolist():
                    structure["file_sizes"][file_info.filename] = file_info.file_size
                   
                    # åˆ†ç±»æ–‡ä»¶
                    if file_info.filename.endswith('.dex'):
                        structure["dex_files"].append(file_info.filename)
                    elif file_info.filename.endswith('.so'):
                        structure["so_files"].append(file_info.filename)
                    elif file_info.filename.startswith('res/'):
                        structure["resource_files"].append(file_info.filename)
                    elif file_info.filename == 'AndroidManifest.xml':
                        structure["manifest_found"] = True
                    elif 'META-INF' in file_info.filename and '.RSA' in file_info.filename:
                        structure["certificate_found"] = True
               
                # æå–å…³é”®æ–‡ä»¶
                zip_ref.extractall(self.temp_dir)
               
            print(f"  âœ“ æå–äº† {len(structure['file_list'])} ä¸ªæ–‡ä»¶")
            print(f"  âœ“ æ‰¾åˆ° {len(structure['dex_files'])} ä¸ªDEXæ–‡ä»¶")
            print(f"  âœ“ æ‰¾åˆ° {len(structure['so_files'])} ä¸ªSOåº“")
           
        except Exception as e:
            print(f"  âœ— æå–å¤±è´¥: {e}")
           
        return structure
   
    def analyze_manifest(self) -> Dict[str, Any]:
        """åˆ†æAndroidManifest.xmlï¼ˆéœ€è¦apktoolæˆ–aaptï¼‰"""
        print("\nğŸ“„ æ­£åœ¨åˆ†æAndroidManifest.xml...")
       
        manifest_info = {
            "raw_available": False,
            "permissions": [],
            "activities": [],
            "services": [],
            "receivers": [],
            "providers": [],
            "package_name": "",
            "version_code": "",
            "version_name": "",
            "min_sdk": "",
            "target_sdk": ""
        }
       
        try:
            # å°è¯•ä½¿ç”¨aaptè¯»å–
            aapt_path = shutil.which('aapt')
            if aapt_path:
                result = subprocess.run(
                    [aapt_path, 'dump', 'badging', self.apk_path],
                    capture_output=True,
                    text=True
                )
               
                if result.returncode == 0:
                    output = result.stdout
                   
                    # æå–åŒ…å
                    package_match = re.search(r"package: name='([^']+)'", output)
                    if package_match:
                        manifest_info["package_name"] = package_match.group(1)
                   
                    # æå–ç‰ˆæœ¬ä¿¡æ¯
                    version_match = re.search(r"versionCode='([^']+)'.*versionName='([^']+)'", output)
                    if version_match:
                        manifest_info["version_code"] = version_match.group(1)
                        manifest_info["version_name"] = version_match.group(2)
                   
                    # æå–SDKç‰ˆæœ¬
                    sdk_match = re.search(r"sdkVersion:'(\d+)'", output)
                    if sdk_match:
                        manifest_info["min_sdk"] = sdk_match.group(1)
                   
                    target_sdk_match = re.search(r"targetSdkVersion:'(\d+)'", output)
                    if target_sdk_match:
                        manifest_info["target_sdk"] = target_sdk_match.group(1)
                   
                    # æå–æƒé™
                    permissions = re.findall(r"uses-permission: name='([^']+)'", output)
                    manifest_info["permissions"] = permissions
                   
                    manifest_info["raw_available"] = True
                    print(f"  âœ“ åŒ…å: {manifest_info['package_name']}")
                    print(f"  âœ“ ç‰ˆæœ¬: {manifest_info['version_name']} ({manifest_info['version_code']})")
                    print(f"  âœ“ æ‰¾åˆ° {len(permissions)} ä¸ªæƒé™")
            else:
                print("  âš ï¸  æœªæ‰¾åˆ°aaptå·¥å…·ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
               
        except Exception as e:
            print(f"  âœ— åˆ†æå¤±è´¥: {e}")
           
        return manifest_info
   
    def analyze_dex_files(self, structure: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æDEXæ–‡ä»¶ä¿¡æ¯"""
        print("\nğŸ” æ­£åœ¨åˆ†æDEXæ–‡ä»¶...")
       
        dex_info = {
            "count": len(structure["dex_files"]),
            "files": [],
            "total_size": 0,
            "estimated_methods": 0
        }
       
        for dex_file in structure["dex_files"]:
            file_path = os.path.join(self.temp_dir, dex_file)
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                dex_info["total_size"] += size
                dex_info["files"].append({
                    "name": dex_file,
                    "size": size,
                    "size_mb": round(size / 1024 / 1024, 2)
                })
       
        # ç²—ç•¥ä¼°è®¡æ–¹æ³•æ•°ï¼ˆæ¯ä¸ªæ–¹æ³•å¤§çº¦100-200å­—èŠ‚ï¼‰
        dex_info["estimated_methods"] = int(dex_info["total_size"] / 150)
       
        print(f"  âœ“ DEXæ–‡ä»¶æ•°: {dex_info['count']}")
        print(f"  âœ“ DEXæ€»å¤§å°: {round(dex_info['total_size'] / 1024 / 1024, 2)} MB")
        print(f"  âœ“ ä¼°è®¡æ–¹æ³•æ•°: {dex_info['estimated_methods']}")
       
        return dex_info
   
    def analyze_native_libs(self, structure: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æNativeåº“"""
        print("\nğŸ”§ æ­£åœ¨åˆ†æNativeåº“...")
       
        native_info = {
            "architectures": {},
            "libraries": [],
            "total_size": 0
        }
       
        for so_file in structure["so_files"]:
            # æå–æ¶æ„ä¿¡æ¯
            parts = so_file.split('/')
            if len(parts) >= 2 and parts[0] == 'lib':
                arch = parts[1]
                lib_name = parts[-1]
               
                if arch not in native_info["architectures"]:
                    native_info["architectures"][arch] = []
               
                file_path = os.path.join(self.temp_dir, so_file)
                if os.path.exists(file_path):
                    size = os.path.getsize(file_path)
                    native_info["total_size"] += size
                    native_info["architectures"][arch].append({
                        "name": lib_name,
                        "size": size
                    })
                   
                    if lib_name not in [lib["name"] for lib in native_info["libraries"]]:
                        native_info["libraries"].append({
                            "name": lib_name,
                            "architectures": [arch]
                        })
       
        print(f"  âœ“ æ”¯æŒçš„æ¶æ„: {', '.join(native_info['architectures'].keys())}")
        print(f"  âœ“ åº“æ–‡ä»¶æ•°: {len(native_info['libraries'])}")
        print(f"  âœ“ Nativeä»£ç æ€»å¤§å°: {round(native_info['total_size'] / 1024 / 1024, 2)} MB")
       
        return native_info
   
    def extract_resources_info(self) -> Dict[str, Any]:
        """æå–èµ„æºä¿¡æ¯"""
        print("\nğŸ¨ æ­£åœ¨åˆ†æèµ„æºæ–‡ä»¶...")
       
        resources_info = {
            "has_resources_arsc": False,
            "layout_count": 0,
            "drawable_count": 0,
            "xml_count": 0,
            "asset_files": []
        }
       
        resources_arsc = os.path.join(self.temp_dir, "resources.arsc")
        if os.path.exists(resources_arsc):
            resources_info["has_resources_arsc"] = True
            resources_info["arsc_size"] = os.path.getsize(resources_arsc)
       
        # ç»Ÿè®¡èµ„æºæ–‡ä»¶
        res_dir = os.path.join(self.temp_dir, "res")
        if os.path.exists(res_dir):
            for root, dirs, files in os.walk(res_dir):
                for file in files:
                    if 'layout' in root:
                        resources_info["layout_count"] += 1
                    elif 'drawable' in root or 'mipmap' in root:
                        resources_info["drawable_count"] += 1
                    elif file.endswith('.xml'):
                        resources_info["xml_count"] += 1
       
        # ç»Ÿè®¡assets
        assets_dir = os.path.join(self.temp_dir, "assets")
        if os.path.exists(assets_dir):
            for root, dirs, files in os.walk(assets_dir):
                for file in files:
                    rel_path = os.path.relpath(os.path.join(root, file), assets_dir)
                    resources_info["asset_files"].append(rel_path)
       
        print(f"  âœ“ å¸ƒå±€æ–‡ä»¶: {resources_info['layout_count']}")
        print(f"  âœ“ å›¾åƒèµ„æº: {resources_info['drawable_count']}")
        print(f"  âœ“ Assetsæ–‡ä»¶: {len(resources_info['asset_files'])}")
       
        return resources_info
   
    def analyze_signature(self) -> Dict[str, Any]:
        """åˆ†æç­¾åä¿¡æ¯"""
        print("\nğŸ” æ­£åœ¨åˆ†æç­¾åä¿¡æ¯...")
       
        signature_info = {
            "signed": False,
            "certificates": [],
            "signature_versions": []
        }
       
        try:
            # æ£€æŸ¥META-INFç›®å½•
            meta_inf_dir = os.path.join(self.temp_dir, "META-INF")
            if os.path.exists(meta_inf_dir):
                cert_files = [f for f in os.listdir(meta_inf_dir) if f.endswith(('.RSA', '.DSA', '.EC'))]
                signature_info["signed"] = len(cert_files) > 0
                signature_info["certificates"] = cert_files
               
                # æ£€æŸ¥ç­¾åç‰ˆæœ¬
                if os.path.exists(os.path.join(meta_inf_dir, "MANIFEST.MF")):
                    signature_info["signature_versions"].append("v1 (JAR)")
               
            print(f"  âœ“ å·²ç­¾å: {signature_info['signed']}")
            print(f"  âœ“ è¯ä¹¦æ–‡ä»¶: {len(signature_info['certificates'])}")
           
        except Exception as e:
            print(f"  âœ— åˆ†æå¤±è´¥: {e}")
           
        return signature_info
   
    def detect_packer(self) -> Dict[str, Any]:
        """æ£€æµ‹åŠ å£³"""
        print("\nğŸ›¡ï¸  æ­£åœ¨æ£€æµ‹åŠ å£³...")
       
        packer_info = {
            "is_packed": False,
            "packer_name": None,
            "confidence": 0,
            "indicators": [],
            "entry_class": None,
            "difficulty": "æœªçŸ¥"
        }
       
        # åŠ å£³ç‰¹å¾åº“
        packer_signatures = {
            "360åŠ å›º": {
                "signatures": ["com.stub.StubApp", "com.qihoo.util", "com.qihoo360", "libjiagu"],
                "difficulty": "ä¸­"
            },
            "è…¾è®¯ä¹å›º": {
                "signatures": ["com.tencent.StubShell", "com.tencent.bugly", "libtup", "libshell"],
                "difficulty": "é«˜"
            },
            "æ¢†æ¢†åŠ å›º": {
                "signatures": ["com.secneo.apkwrapper", "com.bangcle", "libsecexe", "libDexHelper"],
                "difficulty": "é«˜"
            },
            "çˆ±åŠ å¯†": {
                "signatures": ["com.ijiami", "s.h.e.l.l", "libijiami", "libexec"],
                "difficulty": "ä¸­é«˜"
            },
            "å¨œè¿¦åŠ å›º": {
                "signatures": ["com.nagain", "com.naga", "libnaga", "libddog"],
                "difficulty": "ä¸­"
            },
            "é˜¿é‡Œèšå®‰å…¨": {
                "signatures": ["com.alibaba.wireless.security", "libsgmain", "libmobisec"],
                "difficulty": "é«˜"
            },
            "ç™¾åº¦åŠ å›º": {
                "signatures": ["com.baidu.protect", "libbaiduprotect"],
                "difficulty": "ä¸­"
            },
            "ç½‘æ˜“æ˜“ç›¾": {
                "signatures": ["com.netease.nis", "libnesec"],
                "difficulty": "ä¸­é«˜"
            },
            "é¡¶è±¡åŠ å›º": {
                "signatures": ["com.dingxiang.mobile", "libdxshield"],
                "difficulty": "é«˜"
            },
        }
       
        try:
            # ç®€å•çš„ç‰¹å¾æ£€æµ‹ï¼šæ£€æŸ¥æ–‡ä»¶åˆ—è¡¨ä¸­çš„å…³é”®å­—
            all_files = self.extracted_info.get('structure', {}).get('file_list', [])
            so_files = self.extracted_info.get('structure', {}).get('so_files', [])
           
            matched_packers = []
            for packer_name, packer_data in packer_signatures.items():
                signatures = packer_data['signatures']
                matches = []
               
                # æ£€æŸ¥æ–‡ä»¶è·¯å¾„ä¸­çš„ç‰¹å¾
                for signature in signatures:
                    for file_path in all_files + so_files:
                        if signature.lower() in file_path.lower():
                            matches.append(f"æ–‡ä»¶è·¯å¾„åŒ…å«: {signature}")
                            break
               
                if matches:
                    matched_packers.append({
                        "name": packer_name,
                        "matches": matches,
                        "confidence": min(len(matches) * PACKER_CONFIDENCE_MULTIPLIER, 90),  # é™åˆ¶æœ€å¤§90%
                        "difficulty": packer_data['difficulty']
                    })
           
            # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„åŠ å£³æ–¹æ¡ˆ
            if matched_packers:
                matched_packers.sort(key=lambda x: x['confidence'], reverse=True)
                best_match = matched_packers[0]
               
                packer_info["is_packed"] = True
                packer_info["packer_name"] = best_match['name']
                packer_info["confidence"] = min(best_match['confidence'], 90)
                packer_info["indicators"] = best_match['matches']
                packer_info["difficulty"] = best_match['difficulty']
               
                print(f"  âš ï¸  æ£€æµ‹åˆ°åŠ å£³: {best_match['name']}")
                print(f"  âš ï¸  ç½®ä¿¡åº¦: {packer_info['confidence']}%")
                print(f"  âš ï¸  è„±å£³éš¾åº¦: {best_match['difficulty']}")
            else:
                print(f"  âœ“ æœªæ£€æµ‹åˆ°å¸¸è§åŠ å£³")
               
        except Exception as e:
            print(f"  âœ— åŠ å£³æ£€æµ‹å¤±è´¥: {e}")
           
        return packer_info
   
    def detect_obfuscation(self) -> Dict[str, Any]:
        """æ£€æµ‹æ··æ·†"""
        print("\nğŸ”€ æ­£åœ¨æ£€æµ‹æ··æ·†...")
       
        obfuscation_info = {
            "is_obfuscated": False,
            "obfuscation_level": 0,  # 1-10
            "identifier_obfuscation": False,
            "string_encryption": False,
            "control_flow_obfuscation": False,
            "details": {
                "short_names_ratio": 0,
                "single_char_names": 0,
                "obfuscated_packages": []
            }
        }
       
        try:
            # åˆ†æåŒ…åå’Œç±»åç‰¹å¾
            package_name = self.extracted_info.get('manifest', {}).get('package_name', '')
           
            # æ£€æµ‹åŒ…åæ··æ·†
            if package_name:
                # æ£€æŸ¥æ˜¯å¦æœ‰çŸ­ç±»åæˆ–å•å­—ç¬¦åŒ…å
                package_parts = package_name.split('.')
                short_parts = [p for p in package_parts if len(p) <= 2]
               
                if short_parts:
                    obfuscation_info["identifier_obfuscation"] = True
                    obfuscation_info["details"]["obfuscated_packages"].append(package_name)
           
            # åˆ†æDEXæ–‡ä»¶æ•°é‡å’Œå¤§å°
            dex_count = self.extracted_info.get('dex', {}).get('count', 0)
            if dex_count > 1:
                # å¤šDEXå¯èƒ½æš—ç¤ºä½¿ç”¨äº†æ··æ·†
                obfuscation_info["obfuscation_level"] += 2
           
            # æ£€æŸ¥æ˜¯å¦æœ‰ProGuard/R8çš„æ˜ å°„æ–‡ä»¶
            all_files = self.extracted_info.get('structure', {}).get('file_list', [])
            has_mapping = any('mapping' in f.lower() or 'proguard' in f.lower() for f in all_files)
           
            # åˆ†æNativeåº“ï¼ˆæ··æ·†é€šå¸¸ä¼šæœ‰nativeä»£ç ï¼‰
            native_count = len(self.extracted_info.get('native', {}).get('libraries', []))
            if native_count > 3:
                obfuscation_info["obfuscation_level"] += 1
           
            # ä¼°ç®—æ··æ·†ç­‰çº§
            if obfuscation_info["identifier_obfuscation"]:
                obfuscation_info["obfuscation_level"] += 3
                obfuscation_info["is_obfuscated"] = True
           
            if has_mapping:
                obfuscation_info["obfuscation_level"] += 2
                obfuscation_info["is_obfuscated"] = True
           
            # æ£€æµ‹å¯èƒ½çš„å­—ç¬¦ä¸²åŠ å¯†ï¼ˆé€šè¿‡æ£€æµ‹åŠ å¯†ç›¸å…³çš„åº“ï¼‰
            crypto_libs = [lib['name'] for lib in self.extracted_info.get('native', {}).get('libraries', [])
                          if any(keyword in lib['name'].lower() for keyword in ['crypto', 'cipher', 'encrypt'])]
            if crypto_libs:
                obfuscation_info["string_encryption"] = True
                obfuscation_info["obfuscation_level"] += 2
           
            # é™åˆ¶åœ¨1-10èŒƒå›´å†…
            obfuscation_info["obfuscation_level"] = min(obfuscation_info["obfuscation_level"], 10)
           
            if obfuscation_info["is_obfuscated"]:
                print(f"  âš ï¸  æ£€æµ‹åˆ°ä»£ç æ··æ·†")
                print(f"  âš ï¸  æ··æ·†ç­‰çº§: {obfuscation_info['obfuscation_level']}/10")
            else:
                print(f"  âœ“ æœªæ£€æµ‹åˆ°æ˜æ˜¾æ··æ·†")
               
        except Exception as e:
            print(f"  âœ— æ··æ·†æ£€æµ‹å¤±è´¥: {e}")
           
        return obfuscation_info
   
    def decompile_apk(self) -> Dict[str, Any]:
        """åç¼–è¯‘APK"""
        print("\nğŸ”“ æ­£åœ¨åç¼–è¯‘APK...")
       
        decompile_info = {
            "success": False,
            "method": None,
            "output_dir": None,
            "java_sources": [],
            "smali_sources": [],
            "error": None
        }
       
        if not self.enable_decompile:
            print("  âš ï¸  åç¼–è¯‘åŠŸèƒ½æœªå¯ç”¨")
            return decompile_info
       
        if not self.decompiler_tools:
            print("  âš ï¸  æœªæ‰¾åˆ°åç¼–è¯‘å·¥å…·")
            decompile_info["error"] = "æœªæ‰¾åˆ°åç¼–è¯‘å·¥å…·"
            return decompile_info
       
        try:
            # å°è¯•ä½¿ç”¨jadxåç¼–è¯‘
            if 'jadx' in self.decompiler_tools:
                print("  â†’ ä½¿ç”¨jadxè¿›è¡Œåç¼–è¯‘...")
                jadx_output = os.path.join(self.output_dir, 'jadx_output')
                os.makedirs(jadx_output, exist_ok=True)
               
                result = subprocess.run(
                    [self.decompiler_tools['jadx'], '-d', jadx_output, self.apk_path, '--show-bad-code'],
                    capture_output=True,
                    text=True,
                    timeout=DECOMPILE_TIMEOUT  # åç¼–è¯‘è¶…æ—¶
                )
               
                if result.returncode == 0 or os.path.exists(os.path.join(jadx_output, 'sources')):
                    decompile_info["success"] = True
                    decompile_info["method"] = "jadx"
                    decompile_info["output_dir"] = jadx_output
                    self.decompile_dir = jadx_output
                   
                    # ç»Ÿè®¡åç¼–è¯‘çš„Javaæ–‡ä»¶
                    sources_dir = os.path.join(jadx_output, 'sources')
                    if os.path.exists(sources_dir):
                        for root, dirs, files in os.walk(sources_dir):
                            for file in files:
                                if file.endswith('.java'):
                                    rel_path = os.path.relpath(os.path.join(root, file), sources_dir)
                                    decompile_info["java_sources"].append(rel_path)
                   
                    print(f"  âœ“ jadxåç¼–è¯‘æˆåŠŸ")
                    print(f"  âœ“ è¾“å‡ºç›®å½•: {jadx_output}")
                    print(f"  âœ“ Javaæºæ–‡ä»¶æ•°: {len(decompile_info['java_sources'])}")
                else:
                    print(f"  âœ— jadxåç¼–è¯‘å¤±è´¥: {result.stderr}")
           
            # å°è¯•ä½¿ç”¨apktoolåç¼–è¯‘
            if 'apktool' in self.decompiler_tools and not decompile_info["success"]:
                print("  â†’ ä½¿ç”¨apktoolè¿›è¡Œåç¼–è¯‘...")
                apktool_output = os.path.join(self.output_dir, 'apktool_output')
                os.makedirs(apktool_output, exist_ok=True)
               
                result = subprocess.run(
                    [self.decompiler_tools['apktool'], 'd', self.apk_path, '-o', apktool_output, '-f'],
                    capture_output=True,
                    text=True,
                    timeout=DECOMPILE_TIMEOUT
                )
               
                if result.returncode == 0 and os.path.exists(apktool_output):
                    decompile_info["success"] = True
                    decompile_info["method"] = "apktool"
                    decompile_info["output_dir"] = apktool_output
                    self.decompile_dir = apktool_output
                   
                    # ç»Ÿè®¡åç¼–è¯‘çš„Smaliæ–‡ä»¶
                    smali_dir = os.path.join(apktool_output, 'smali')
                    if os.path.exists(smali_dir):
                        for root, dirs, files in os.walk(smali_dir):
                            for file in files:
                                if file.endswith('.smali'):
                                    rel_path = os.path.relpath(os.path.join(root, file), smali_dir)
                                    decompile_info["smali_sources"].append(rel_path)
                   
                    print(f"  âœ“ apktoolåç¼–è¯‘æˆåŠŸ")
                    print(f"  âœ“ è¾“å‡ºç›®å½•: {apktool_output}")
                    print(f"  âœ“ Smaliæºæ–‡ä»¶æ•°: {len(decompile_info['smali_sources'])}")
                else:
                    print(f"  âœ— apktoolåç¼–è¯‘å¤±è´¥: {result.stderr}")
                    decompile_info["error"] = result.stderr
           
        except subprocess.TimeoutExpired:
            print(f"  âœ— åç¼–è¯‘è¶…æ—¶")
            decompile_info["error"] = "åç¼–è¯‘è¶…æ—¶"
        except Exception as e:
            print(f"  âœ— åç¼–è¯‘å¤±è´¥: {e}")
            decompile_info["error"] = str(e)
           
        return decompile_info
   
    def analyze_code_logic(self, decompile_info: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æä»£ç é€»è¾‘"""
        print("\nğŸ§  æ­£åœ¨åˆ†æä»£ç é€»è¾‘...")
       
        logic_info = {
            "entry_points": [],      # å…¥å£ç‚¹
            "key_classes": [],       # å…³é”®ç±»
            "sensitive_methods": [], # æ•æ„Ÿæ–¹æ³•
            "modifiable_points": [], # å¯ä¿®æ”¹ç‚¹
            "hook_suggestions": []   # Hook å»ºè®®
        }
       
        if not decompile_info.get("success"):
            print("  âš ï¸  åç¼–è¯‘æœªæˆåŠŸï¼Œè·³è¿‡ä»£ç é€»è¾‘åˆ†æ")
            return logic_info
       
        try:
            decompile_dir = decompile_info.get("output_dir")
            if not decompile_dir or not os.path.exists(decompile_dir):
                print("  âš ï¸  åç¼–è¯‘ç›®å½•ä¸å­˜åœ¨")
                return logic_info
           
            # åˆ†æAndroidManifest.xmlï¼ˆä»apktoolè¾“å‡ºï¼‰
            manifest_path = os.path.join(decompile_dir, 'AndroidManifest.xml')
            if os.path.exists(manifest_path):
                with open(manifest_path, 'r', encoding='utf-8', errors='ignore') as f:
                    manifest_content = f.read()
                   
                # æå–Activity
                activities = re.findall(r'<activity[^>]*android:name="([^"]+)"', manifest_content)
                for activity in activities[:10]:  # é™åˆ¶æ•°é‡
                    logic_info["entry_points"].append({
                        "type": "Activity",
                        "name": activity,
                        "description": "åº”ç”¨ç•Œé¢å…¥å£"
                    })
                    logic_info["key_classes"].append(activity)
               
                # æå–Service
                services = re.findall(r'<service[^>]*android:name="([^"]+)"', manifest_content)
                for service in services[:10]:
                    logic_info["entry_points"].append({
                        "type": "Service",
                        "name": service,
                        "description": "åå°æœåŠ¡"
                    })
                    logic_info["key_classes"].append(service)
               
                # æå–BroadcastReceiver
                receivers = re.findall(r'<receiver[^>]*android:name="([^"]+)"', manifest_content)
                for receiver in receivers[:10]:
                    logic_info["entry_points"].append({
                        "type": "BroadcastReceiver",
                        "name": receiver,
                        "description": "å¹¿æ’­æ¥æ”¶å™¨"
                    })
                    logic_info["key_classes"].append(receiver)
           
            # åˆ†æJava/Smaliæºä»£ç ï¼ŒæŸ¥æ‰¾æ•æ„Ÿæ–¹æ³•
            sources_dir = os.path.join(decompile_dir, 'sources')
            smali_dir = os.path.join(decompile_dir, 'smali')
           
            # æ•æ„Ÿå…³é”®è¯
            sensitive_keywords = {
                "ç½‘ç»œè¯·æ±‚": ["HttpURLConnection", "OkHttp", "Retrofit", "URLConnection", "HttpClient"],
                "æ–‡ä»¶æ“ä½œ": ["FileOutputStream", "FileInputStream", "File.write", "File.read"],
                "åŠ å¯†è§£å¯†": ["Cipher", "MessageDigest", "SecretKey", "encrypt", "decrypt", "AES", "DES", "RSA"],
                "ç­¾åéªŒè¯": ["Signature", "PackageManager.GET_SIGNATURES", "checkSignature", "verifySignature"],
                "åŠ¨æ€åŠ è½½": ["DexClassLoader", "PathClassLoader", "loadClass", "loadDex"],
                "åå°„è°ƒç”¨": ["Class.forName", "Method.invoke", "getDeclaredMethod"],
                "Nativeè°ƒç”¨": ["System.loadLibrary", "JNI", "native "],
                "æ•°æ®åº“æ“ä½œ": ["SQLiteDatabase", "ContentProvider", "query", "insert", "update"],
                "SharedPreferences": ["SharedPreferences", "getSharedPreferences", "edit().put"],
                "Rootæ£€æµ‹": ["su", "Superuser", "isRooted", "checkRoot"]
            }
           
            # æ‰«æJavaæºæ–‡ä»¶
            if os.path.exists(sources_dir):
                java_files = decompile_info.get("java_sources", [])[:MAX_SCAN_FILES]  # é™åˆ¶æ‰«ææ–‡ä»¶æ•°
                for java_file in java_files:
                    file_path = os.path.join(sources_dir, java_file)
                    if os.path.exists(file_path):
                        try:
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                content = f.read()
                               
                            for category, keywords in sensitive_keywords.items():
                                for keyword in keywords:
                                    if keyword in content:
                                        logic_info["sensitive_methods"].append({
                                            "category": category,
                                            "keyword": keyword,
                                            "file": java_file,
                                            "description": f"åœ¨{java_file}ä¸­å‘ç°{category}æ“ä½œ"
                                        })
                                        break
                        except Exception:
                            continue
           
            # ç”Ÿæˆå¯ä¿®æ”¹ç‚¹å»ºè®®
            if logic_info["sensitive_methods"]:
                # ç­¾åéªŒè¯ç›¸å…³
                signature_related = [m for m in logic_info["sensitive_methods"] if m["category"] == "ç­¾åéªŒè¯"]
                if signature_related:
                    logic_info["modifiable_points"].append({
                        "point": "ç­¾åéªŒè¯ç»•è¿‡",
                        "description": "æ£€æµ‹åˆ°ç­¾åéªŒè¯ä»£ç ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹éªŒè¯é€»è¾‘ç»•è¿‡ç­¾åæ£€æŸ¥",
                        "files": [m["file"] for m in signature_related],
                        "difficulty": "ä¸­"
                    })
               
                # ç½‘ç»œè¯·æ±‚ç›¸å…³
                network_related = [m for m in logic_info["sensitive_methods"] if m["category"] == "ç½‘ç»œè¯·æ±‚"]
                if network_related:
                    logic_info["modifiable_points"].append({
                        "point": "APIåœ°å€ä¿®æ”¹",
                        "description": "æ£€æµ‹åˆ°ç½‘ç»œè¯·æ±‚ä»£ç ï¼Œå¯ä»¥ä¿®æ”¹APIæœåŠ¡å™¨åœ°å€",
                        "files": list(set([m["file"] for m in network_related])),
                        "difficulty": "ä½"
                    })
               
                # Rootæ£€æµ‹ç›¸å…³
                root_related = [m for m in logic_info["sensitive_methods"] if m["category"] == "Rootæ£€æµ‹"]
                if root_related:
                    logic_info["modifiable_points"].append({
                        "point": "Rootæ£€æµ‹ç»•è¿‡",
                        "description": "æ£€æµ‹åˆ°Rootæ£€æµ‹ä»£ç ï¼Œå¯ä»¥ä¿®æ”¹æ£€æµ‹é€»è¾‘",
                        "files": [m["file"] for m in root_related],
                        "difficulty": "ä½"
                    })
           
            # ç”ŸæˆHookå»ºè®®
            if logic_info["key_classes"]:
                logic_info["hook_suggestions"].append({
                    "target": "Applicationå…¥å£",
                    "classes": [c for c in logic_info["key_classes"] if "Application" in c],
                    "method": "onCreate",
                    "reason": "Hookåº”ç”¨å¯åŠ¨æµç¨‹ï¼Œå¯ä»¥åœ¨åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œè‡ªå®šä¹‰ä»£ç "
                })
           
            if any(m["category"] == "åŠ å¯†è§£å¯†" for m in logic_info["sensitive_methods"]):
                logic_info["hook_suggestions"].append({
                    "target": "åŠ å¯†è§£å¯†æ–¹æ³•",
                    "classes": ["javax.crypto.Cipher"],
                    "method": "doFinal",
                    "reason": "HookåŠ å¯†è§£å¯†æ–¹æ³•ï¼Œå¯ä»¥è·å–æ˜æ–‡æ•°æ®"
                })
           
            if any(m["category"] == "ç½‘ç»œè¯·æ±‚" for m in logic_info["sensitive_methods"]):
                logic_info["hook_suggestions"].append({
                    "target": "ç½‘ç»œè¯·æ±‚",
                    "classes": ["okhttp3.OkHttpClient", "java.net.HttpURLConnection"],
                    "method": "execute / connect",
                    "reason": "Hookç½‘ç»œè¯·æ±‚ï¼Œå¯ä»¥æŸ¥çœ‹æˆ–ä¿®æ”¹è¯·æ±‚å†…å®¹"
                })
           
            print(f"  âœ“ å‘ç° {len(logic_info['entry_points'])} ä¸ªå…¥å£ç‚¹")
            print(f"  âœ“ å‘ç° {len(logic_info['sensitive_methods'])} ä¸ªæ•æ„Ÿæ–¹æ³•")
            print(f"  âœ“ è¯†åˆ« {len(logic_info['modifiable_points'])} ä¸ªå¯ä¿®æ”¹ç‚¹")
            print(f"  âœ“ ç”Ÿæˆ {len(logic_info['hook_suggestions'])} ä¸ªHookå»ºè®®")
           
        except Exception as e:
            print(f"  âœ— ä»£ç é€»è¾‘åˆ†æå¤±è´¥: {e}")
           
        return logic_info
   
    def find_database_files(self, structure: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾APKä¸­çš„æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶"""
        db_files = []
        # æœç´¢ assets ç›®å½•å’Œå…¶ä»–ä½ç½®çš„ .db æ–‡ä»¶
        for file_path in structure.get('file_list', []):
            if file_path.endswith('.db') or file_path.endswith('.sqlite') or file_path.endswith('.sqlite3'):
                full_path = os.path.join(self.temp_dir, file_path)
                db_files.append({
                    'path': file_path,
                    'name': os.path.basename(file_path),
                    'size': os.path.getsize(full_path) if os.path.exists(full_path) else 0
                })
        return db_files
   
    def analyze_database(self, db_path: str) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ•°æ®åº“æ–‡ä»¶"""
        result = {
            'path': db_path,
            'tables': [],
            'total_records': 0,
            'sensitive_data': [],
            'error': None
        }
        
        try:
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                
                # è·å–æ‰€æœ‰è¡¨å
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = cursor.fetchall()
                
                for table in tables:
                    table_name = table[0]
                    # éªŒè¯è¡¨åä»¥é˜²æ­¢SQLæ³¨å…¥ï¼ˆè™½ç„¶æ¥è‡ªsqlite_masterï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼‰
                    # SQLiteè¡¨ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿
                    if not all(c.isalnum() or c == '_' for c in table_name):
                        continue
                    
                    table_info = {
                        'name': table_name,
                        'columns': [],
                        'row_count': 0,
                        'sample_data': []
                    }
                    
                    # è·å–è¡¨ç»“æ„ - PRAGMAå‘½ä»¤æ˜¯å®‰å…¨çš„ï¼Œä¸éœ€è¦å‚æ•°åŒ–
                    cursor.execute(f"PRAGMA table_info({table_name})")
                    columns = cursor.fetchall()
                    table_info['columns'] = [{'name': col[1], 'type': col[2]} for col in columns]
                    
                    # è·å–è¡Œæ•° - ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
                    # Note: SQLite doesn't support parameter substitution for table names in standard queries
                    # But we've validated the table name above
                    cursor.execute(f'SELECT COUNT(*) FROM "{table_name}"')
                    table_info['row_count'] = cursor.fetchone()[0]
                    result['total_records'] += table_info['row_count']
                    
                    # è·å–æ ·æœ¬æ•°æ®ï¼ˆå‰10è¡Œï¼‰
                    cursor.execute(f'SELECT * FROM "{table_name}" LIMIT 10')
                    table_info['sample_data'] = cursor.fetchall()
                    
                    # æ£€æµ‹æ•æ„Ÿæ•°æ®
                    sensitive_keywords = ['password', 'token', 'secret', 'key', 'auth', 'session', 
                                          'user', 'email', 'phone', 'credential', 'cookie']
                    for col in table_info['columns']:
                        col_name_lower = col['name'].lower()
                        for keyword in sensitive_keywords:
                            if keyword in col_name_lower:
                                result['sensitive_data'].append({
                                    'table': table_name,
                                    'column': col['name'],
                                    'keyword': keyword
                                })
                    
                    result['tables'].append(table_info)
        except Exception as e:
            result['error'] = str(e)
        
        return result
   
    def analyze_all_databases(self) -> Dict[str, Any]:
        """åˆ†æAPKä¸­æ‰€æœ‰çš„æ•°æ®åº“æ–‡ä»¶"""
        print("\nğŸ—„ï¸  æ­£åœ¨åˆ†ææ•°æ®åº“æ–‡ä»¶...")
        
        structure = self.extracted_info.get('structure', {})
        db_files = self.find_database_files(structure)
        
        results = {
            'total_databases': len(db_files),
            'databases': []
        }
        
        print(f"  âœ“ æ‰¾åˆ° {len(db_files)} ä¸ªæ•°æ®åº“æ–‡ä»¶")
        
        for db_file in db_files:
            full_path = os.path.join(self.temp_dir, db_file['path'])
            if os.path.exists(full_path):
                print(f"  â†’ åˆ†ææ•°æ®åº“: {db_file['name']}")
                db_analysis = self.analyze_database(full_path)
                # Add size information from db_file
                db_analysis['size'] = db_file.get('size', 0)
                results['databases'].append(db_analysis)
                
                if db_analysis.get('error'):
                    print(f"    âœ— åˆ†æå¤±è´¥: {db_analysis['error']}")
                else:
                    print(f"    âœ“ æ‰¾åˆ° {len(db_analysis.get('tables', []))} ä¸ªè¡¨ï¼Œå…± {db_analysis.get('total_records', 0)} æ¡è®°å½•")
                    if db_analysis.get('sensitive_data'):
                        print(f"    âš ï¸  å‘ç° {len(db_analysis['sensitive_data'])} ä¸ªæ•æ„Ÿå­—æ®µ")
        
        return results
   
    def extract_all(self) -> Dict[str, Any]:
        """æå–æ‰€æœ‰APKä¿¡æ¯"""
        print("\n" + "="*80)
        print("å¼€å§‹æå–APKä¿¡æ¯")
        print("="*80)
       
        all_info = {
            "apk_path": self.apk_path,
            "timestamp": datetime.now().isoformat()
        }
       
        all_info["structure"] = self.extract_basic_structure()
        all_info["manifest"] = self.analyze_manifest()
        all_info["dex"] = self.analyze_dex_files(all_info["structure"])
        all_info["native"] = self.analyze_native_libs(all_info["structure"])
        all_info["resources"] = self.extract_resources_info()
        all_info["signature"] = self.analyze_signature()
       
        # Store for later use by other methods
        self.extracted_info = all_info
        
        # æ·»åŠ æ•°æ®åº“åˆ†æ
        if self.analyze_db:
            all_info['database_analysis'] = self.analyze_all_databases()
       
        return all_info
   
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            shutil.rmtree(self.temp_dir)
        except:
            pass


class OllamaClient:
    """Ollamaå®¢æˆ·ç«¯å°è£… - ä½¿ç”¨HTTP API"""
    
    def __init__(self, model_name: str, base_url: str = "http://127.0.0.1:11434"):
        self.model_name = model_name
        self.base_url = base_url
        
    async def generate(self, prompt: str, context: str = "") -> str:
        """è°ƒç”¨Ollama APIç”Ÿæˆå›å¤"""
        full_prompt = f"{context}\n\n{prompt}" if context else prompt
        
        url = f"{self.base_url}/api/generate"
        payload = {
            "model": self.model_name,
            "prompt": full_prompt,
            "stream": False
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result.get("response", "").strip()
                    else:
                        error = await response.text()
                        print(f"âŒ Ollama APIé”™è¯¯: {error}")
                        return ""
        except aiohttp.ClientConnectorError:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ ({self.base_url})")
            print("   è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ: ollama serve")
            return ""
        except Exception as e:
            print(f"âŒ è°ƒç”¨Ollamaå¤±è´¥: {e}")
            return ""


class AIAgent:
    """AIæ™ºèƒ½ä½“"""
   
    def __init__(self, agent_id: int, model_name: str, role: str, base_url: str = "http://127.0.0.1:11434"):
        self.agent_id = agent_id
        self.model_name = model_name
        self.role = role
        self.base_url = base_url
        self.client = OllamaClient(model_name, base_url)
       
    async def think(self, prompt: str, context: str = "") -> str:
        """æ€è€ƒå¹¶ç”Ÿæˆå›å¤"""
        role_prompt = f"ä½ æ˜¯å®‰å…¨åˆ†æå›¢é˜Ÿæˆå‘˜#{self.agent_id}ï¼Œä¸“é•¿é¢†åŸŸæ˜¯ã€{self.role}ã€‘ã€‚\n\n"
        full_prompt = role_prompt + prompt
        return await self.client.generate(full_prompt, context)
   
    async def vote(self, candidates: List[Dict[str, Any]], task: str) -> int:
        """æŠ•ç¥¨é€‰æ‹©æœ€ä½³è§‚ç‚¹"""
        vote_prompt = f"""
åˆ†æä»»åŠ¡: {task}

ä»¥ä¸‹æ˜¯å›¢é˜Ÿå…¶ä»–æˆå‘˜çš„åˆ†æç»“æœï¼ˆç¼–å·ä»1å¼€å§‹ï¼‰:

"""
        for i, candidate in enumerate(candidates, 1):
            if candidate['agent_id'] != self.agent_id:
                vote_prompt += f"\nåˆ†æ {i} (æ¥è‡ªä¸“å®¶ #{candidate['agent_id']}):\n{candidate['response'][:500]}...\n"
       
        vote_prompt += f"""

ä½ æ˜¯ä¸“å®¶ #{self.agent_id}ï¼Œè¯·æŠ•ç¥¨é€‰æ‹©ä½ è®¤ä¸ºæœ€ä¸“ä¸šã€æœ€å…¨é¢çš„åˆ†æã€‚
æ³¨æ„ï¼šä¸èƒ½æŠ•ç»™è‡ªå·±ï¼ˆåˆ†æ {self.agent_id}ï¼‰ã€‚

è¯·åªè¾“å‡ºä¸€ä¸ªæ•°å­—ï¼ˆ1-6ï¼‰ï¼Œè¡¨ç¤ºä½ é€‰æ‹©çš„åˆ†æç¼–å·ã€‚
ä½ çš„æŠ•ç¥¨:"""
       
        vote_response = await self.client.generate(vote_prompt, "")
       
        # è§£ææŠ•ç¥¨ç»“æœ
        try:
            numbers = re.findall(r'\d+', vote_response)
            if numbers:
                vote = int(numbers[0])
                if 1 <= vote <= 6 and vote != self.agent_id:
                    return vote
                else:
                    valid_votes = [i for i in range(1, 7) if i != self.agent_id]
                    return random.choice(valid_votes)
            else:
                valid_votes = [i for i in range(1, 7) if i != self.agent_id]
                return random.choice(valid_votes)
        except:
            valid_votes = [i for i in range(1, 7) if i != self.agent_id]
            return random.choice(valid_votes)


class AITeam:
    """AIåˆ†æå›¢é˜Ÿ - 6ä¸ªä¸“å®¶ç»„æˆ"""
   
    def __init__(self, team_id: int, role: str, models: List[str], base_url: str = "http://127.0.0.1:11434"):
        self.team_id = team_id
        self.role = role
        self.base_url = base_url
        self.agents = [
            AIAgent(i + 1, models[i % len(models)], role, base_url)
            for i in range(6)
        ]
       
    async def collaborate(self, task: str, context: str = "") -> Dict[str, Any]:
        """å›¢é˜Ÿåä½œåˆ†æ"""
        print(f"\n{'='*80}")
        print(f"å›¢é˜Ÿ #{self.team_id} - ä¸“é•¿: {self.role}")
        print(f"{'='*80}")
       
        # æ‰€æœ‰AIå¹¶è¡Œåˆ†æ
        tasks = [agent.think(task, context) for agent in self.agents]
        responses = await asyncio.gather(*tasks)
       
        # æ˜¾ç¤ºå„AIçš„åˆ†æ
        print(f"\nã€åˆæ­¥åˆ†æç»“æœã€‘")
        for i, response in enumerate(responses):
            print(f"\nä¸“å®¶ #{i+1} çš„åˆ†æ:")
            print(f"{response[:300]}..." if len(response) > 300 else response)
       
        # æŠ•ç¥¨å…±è¯†
        consensus = await self._voting_consensus(responses, task, context)
       
        return {
            "team_id": self.team_id,
            "role": self.role,
            "individual_responses": responses,
            "consensus": consensus,
            "timestamp": datetime.now().isoformat()
        }
   
    async def _voting_consensus(self, responses: List[str], task: str, context: str) -> str:
        """æŠ•ç¥¨å…±è¯†ç®—æ³•"""
        print(f"\n{'='*80}")
        print(f"å¼€å§‹æŠ•ç¥¨å…±è¯†è¿‡ç¨‹")
        print(f"{'='*80}")
       
        candidates = [
            {"agent_id": i + 1, "response": resp, "votes": 0}
            for i, resp in enumerate(responses)
        ]
       
        round_num = 1
       
        while len(candidates) > 1:
            print(f"\nã€ç¬¬ {round_num} è½®æŠ•ç¥¨ã€‘")
            print(f"å½“å‰å‰©ä½™åˆ†æ: {len(candidates)}")
           
            for candidate in candidates:
                candidate['votes'] = 0
           
            vote_tasks = []
            for agent in self.agents:
                vote_tasks.append(agent.vote(candidates, task))
           
            votes = await asyncio.gather(*vote_tasks)
           
            print(f"\næŠ•ç¥¨ç»“æœ:")
            for i, vote in enumerate(votes, 1):
                print(f"  ä¸“å®¶ #{i} æŠ•ç»™äº†åˆ†æ {vote}")
                for candidate in candidates:
                    if candidate['agent_id'] == vote:
                        candidate['votes'] += 1
                        break
           
            print(f"\nå¾—ç¥¨ç»Ÿè®¡:")
            for candidate in sorted(candidates, key=lambda x: x['votes'], reverse=True):
                print(f"  åˆ†æ {candidate['agent_id']}: {candidate['votes']} ç¥¨")
           
            min_votes = min(c['votes'] for c in candidates)
            eliminated = [c for c in candidates if c['votes'] == min_votes]
           
            if len(eliminated) == len(candidates):
                eliminated = [random.choice(candidates)]
           
            if len(eliminated) > 1:
                eliminated = [random.choice(eliminated)]
           
            print(f"\nâŒ æ·˜æ±°åˆ†æ {eliminated[0]['agent_id']} (å¾—ç¥¨ {eliminated[0]['votes']})")
           
            candidates = [c for c in candidates if c['agent_id'] != eliminated[0]['agent_id']]
           
            round_num += 1
       
        winner = candidates[0]
        print(f"\n{'='*80}")
        print(f"âœ“ æŠ•ç¥¨ç»“æŸï¼æœ€ä½³åˆ†æ: ä¸“å®¶ #{winner['agent_id']}")
        print(f"{'='*80}")
        print(f"\næœ€ç»ˆå…±è¯†:")
        print(winner['response'])
       
        return winner['response']


class APKAnalysisOrchestrator:
    """APKåˆ†æç¼–æ’å™¨"""
   
    def __init__(self, models: List[str], apk_path: str, requirements: str = "", 
                 enable_decompile: bool = False, output_dir: str = None, base_url: str = "http://127.0.0.1:11434", 
                 analyze_db: bool = False):
        self.models = models
        self.apk_path = apk_path
        self.requirements = requirements
        self.enable_decompile = enable_decompile
        self.output_dir = output_dir
        self.base_url = base_url
        self.analyze_db = analyze_db
        self.extractor = APKExtractor(apk_path, enable_decompile, output_dir, analyze_db)
        self.apk_info = {}
        self.analysis_results = []
        self.packer_info = {}
        self.obfuscation_info = {}
        self.decompile_info = {}
        self.code_logic_info = {}
       
    async def analyze_packer_and_obfuscation(self) -> Dict[str, Any]:
        """åˆ†æ0: åŠ å£³ä¸æ··æ·†æ£€æµ‹"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 0: åŠ å£³ä¸æ··æ·†æ£€æµ‹")
        print("="*80)
       
        # æ‰§è¡Œæ£€æµ‹
        self.packer_info = self.extractor.detect_packer()
        self.obfuscation_info = self.extractor.detect_obfuscation()
       
        # å¦‚æœå¯ç”¨äº†åç¼–è¯‘ï¼Œæ‰§è¡Œåç¼–è¯‘
        if self.enable_decompile:
            self.decompile_info = self.extractor.decompile_apk()
       
        team = AITeam(0, "åŠ å£³ä¸æ··æ·†åˆ†æä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·åˆ†æä»¥ä¸‹APKçš„åŠ å£³ä¸æ··æ·†æƒ…å†µ:

ã€åŠ å£³æ£€æµ‹ç»“æœã€‘
- æ˜¯å¦åŠ å£³: {self.packer_info.get('is_packed', False)}
- åŠ å£³æ–¹æ¡ˆ: {self.packer_info.get('packer_name', 'æ— ')}
- ç½®ä¿¡åº¦: {self.packer_info.get('confidence', 0)}%
- è„±å£³éš¾åº¦: {self.packer_info.get('difficulty', 'æœªçŸ¥')}
- æ£€æµ‹æŒ‡æ ‡: {', '.join(self.packer_info.get('indicators', []))}

ã€æ··æ·†æ£€æµ‹ç»“æœã€‘
- æ˜¯å¦æ··æ·†: {self.obfuscation_info.get('is_obfuscated', False)}
- æ··æ·†ç­‰çº§: {self.obfuscation_info.get('obfuscation_level', 0)}/10
- æ ‡è¯†ç¬¦æ··æ·†: {self.obfuscation_info.get('identifier_obfuscation', False)}
- å­—ç¬¦ä¸²åŠ å¯†: {self.obfuscation_info.get('string_encryption', False)}
- æ§åˆ¶æµæ··æ·†: {self.obfuscation_info.get('control_flow_obfuscation', False)}

ã€åç¼–è¯‘æƒ…å†µã€‘
- åç¼–è¯‘å¯ç”¨: {self.enable_decompile}
- åç¼–è¯‘æˆåŠŸ: {self.decompile_info.get('success', False)}
- åç¼–è¯‘æ–¹æ³•: {self.decompile_info.get('method', 'æœªæ‰§è¡Œ')}
- Javaæºæ–‡ä»¶æ•°: {len(self.decompile_info.get('java_sources', []))}
- Smaliæºæ–‡ä»¶æ•°: {len(self.decompile_info.get('smali_sources', []))}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æ:

1. **åŠ å£³æŠ€æœ¯è¯„ä¼°**:
   - åŠ å£³æ–¹æ¡ˆçš„ç‰¹ç‚¹å’Œå¼ºåº¦
   - è„±å£³çš„éš¾åº¦å’Œæ–¹æ³•å»ºè®®
   - åŠ å£³å¯¹é€†å‘åˆ†æçš„å½±å“

2. **æ··æ·†æŠ€æœ¯è¯„ä¼°**:
   - æ··æ·†æ–¹æ¡ˆçš„ç±»å‹ï¼ˆProGuard/R8/DexGuardç­‰ï¼‰
   - æ··æ·†å¼ºåº¦å’Œè¦†ç›–èŒƒå›´
   - åæ··æ·†çš„éš¾åº¦å’Œç­–ç•¥

3. **ç»¼åˆä¿æŠ¤è¯„ä¼°**:
   - åŠ å£³+æ··æ·†çš„ç»„åˆæ•ˆæœ
   - æ•´ä½“ä¿æŠ¤å¼ºåº¦è¯„åˆ†
   - é€†å‘å·¥ç¨‹çš„åˆ‡å…¥ç‚¹

4. **åˆ†æå»ºè®®**:
   - æ¨èçš„åˆ†æå·¥å…·å’Œæ–¹æ³•
   - ç»•è¿‡ä¿æŠ¤çš„ç­–ç•¥
   - éœ€è¦æ³¨æ„çš„éš¾ç‚¹
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›ä¸“ä¸šçš„åŠ å£³ä¸æ··æ·†åˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps({
            "packer": self.packer_info,
            "obfuscation": self.obfuscation_info,
            "decompile": self.decompile_info
        }, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def analyze_structure_and_metadata(self) -> Dict[str, Any]:
        """åˆ†æ1: APKæ„æˆä¸å…ƒæ•°æ®"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 1: APKæ„æˆä¸å…ƒæ•°æ®åˆ†æ")
        print("="*80)
       
        team = AITeam(1, "APKç»“æ„ä¸å…ƒæ•°æ®åˆ†æä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·æ·±å…¥åˆ†æä»¥ä¸‹APKçš„æ„æˆä¸å…ƒæ•°æ®:

ã€åŸºæœ¬ä¿¡æ¯ã€‘
- APKè·¯å¾„: {self.apk_info['apk_path']}
- åŒ…å: {self.apk_info['manifest'].get('package_name', 'æœªçŸ¥')}
- ç‰ˆæœ¬: {self.apk_info['manifest'].get('version_name', 'æœªçŸ¥')} ({self.apk_info['manifest'].get('version_code', 'æœªçŸ¥')})
- æœ€å°SDK: {self.apk_info['manifest'].get('min_sdk', 'æœªçŸ¥')}
- ç›®æ ‡SDK: {self.apk_info['manifest'].get('target_sdk', 'æœªçŸ¥')}

ã€æ–‡ä»¶ç»“æ„ã€‘
- æ€»æ–‡ä»¶æ•°: {len(self.apk_info['structure']['file_list'])}
- DEXæ–‡ä»¶æ•°: {len(self.apk_info['structure']['dex_files'])}
- Nativeåº“æ•°: {len(self.apk_info['structure']['so_files'])}
- æ€»å¤§å°: {round(self.apk_info['structure']['total_size'] / 1024 / 1024, 2)} MB

ã€æƒé™åˆ—è¡¨ã€‘
{chr(10).join('- ' + p for p in self.apk_info['manifest'].get('permissions', [])[:20])}
{'...(è¿˜æœ‰æ›´å¤š)' if len(self.apk_info['manifest'].get('permissions', [])) > 20 else ''}

ã€ç­¾åä¿¡æ¯ã€‘
- å·²ç­¾å: {self.apk_info['signature']['signed']}
- è¯ä¹¦æ–‡ä»¶: {', '.join(self.apk_info['signature']['certificates'])}

ã€èµ„æºä¿¡æ¯ã€‘
- å¸ƒå±€æ–‡ä»¶: {self.apk_info['resources']['layout_count']}
- å›¾åƒèµ„æº: {self.apk_info['resources']['drawable_count']}
- Assetsæ–‡ä»¶: {len(self.apk_info['resources']['asset_files'])}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œæ·±å…¥åˆ†æ:
1. **AndroidManifest.xmlåˆ†æ**: ç»„ä»¶å£°æ˜çš„åˆç†æ€§ã€æƒé™ä½¿ç”¨çš„å¿…è¦æ€§ã€intent-filterçš„å®‰å…¨æ€§
2. **resources.arsc**: èµ„æºç»„ç»‡ç»“æ„ã€æœ¬åœ°åŒ–æ”¯æŒã€èµ„æºä¿æŠ¤æªæ–½
3. **DEXæ–‡ä»¶**: å¤šDEXç­–ç•¥ã€æ–¹æ³•æ•°è¯„ä¼°ã€MultiDexä½¿ç”¨
4. **Nativeåº“**: æ¶æ„æ”¯æŒã€åº“çš„ç”¨é€”æ¨æµ‹ã€æ½œåœ¨çš„å®‰å…¨è€ƒè™‘
5. **ç­¾åä¸è¯ä¹¦**: ç­¾åç‰ˆæœ¬ã€è¯ä¹¦é“¾å®Œæ•´æ€§ã€é˜²ç¯¡æ”¹æœºåˆ¶
6. **Assets**: ç‰¹æ®Šèµ„æºã€é…ç½®æ–‡ä»¶ã€æ½œåœ¨çš„åŠ¨æ€å†…å®¹
7. **æ•´ä½“è¯„ä¼°**: åº”ç”¨è§„æ¨¡ã€å¤æ‚åº¦ã€å¯èƒ½çš„æŠ€æœ¯æ ˆ
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›ä¸“ä¸šã€è¯¦ç»†çš„åˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, "")
        self.analysis_results.append(result)
        return result
   
    async def analyze_static_code_structure(self) -> Dict[str, Any]:
        """åˆ†æ2: é™æ€ä»£ç ç»“æ„ä¸è¯­ä¹‰"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 2: é™æ€ä»£ç ç»“æ„ä¸è¯­ä¹‰åˆ†æ")
        print("="*80)
       
        team = AITeam(2, "é™æ€ä»£ç åˆ†æä¸“å®¶", self.models, self.base_url)
       
        task = f"""
åŸºäºAPKçš„ä»£ç ç»“æ„ä¿¡æ¯ï¼Œè¯·è¿›è¡Œé™æ€ä»£ç åˆ†æ:

ã€DEXä¿¡æ¯ã€‘
- DEXæ–‡ä»¶æ•°: {self.apk_info['dex']['count']}
- DEXæ€»å¤§å°: {round(self.apk_info['dex']['total_size'] / 1024 / 1024, 2)} MB
- ä¼°è®¡æ–¹æ³•æ•°: {self.apk_info['dex']['estimated_methods']}
- DEXæ–‡ä»¶åˆ—è¡¨: {', '.join([d['name'] for d in self.apk_info['dex']['files']])}

ã€Nativeä»£ç ã€‘
- æ”¯æŒæ¶æ„: {', '.join(self.apk_info['native']['architectures'].keys())}
- åº“æ–‡ä»¶æ•°: {len(self.apk_info['native']['libraries'])}
- Nativeä»£ç æ€»å¤§å°: {round(self.apk_info['native']['total_size'] / 1024 / 1024, 2)} MB

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œæ·±å…¥åˆ†æ:

1. **DEXç»“æ„åˆ†æ**:
   - å•DEX vs å¤šDEXç­–ç•¥
   - æ–¹æ³•æ•°æ˜¯å¦æ¥è¿‘64Ké™åˆ¶
   - DEXåˆ†åŒ…ç­–ç•¥è¯„ä¼°
   - å¯èƒ½çš„ä»£ç ç»„ç»‡æ–¹å¼

2. **ä»£ç è¯­ä¹‰æ¨æ–­**:
   - ä»æƒé™æ¨æ–­ä¸»è¦åŠŸèƒ½æ¨¡å—
   - å¯èƒ½çš„ç¬¬ä¸‰æ–¹SDKï¼ˆå¹¿å‘Šã€ç»Ÿè®¡ã€æ”¯ä»˜ç­‰ï¼‰
   - æ•°æ®æµå‘ï¼ˆæ•æ„Ÿæºâ†’æ±‡èšç‚¹ï¼‰
   - APIä½¿ç”¨æ¨¡å¼

3. **è°ƒç”¨å…³ç³»æ¨æµ‹**:
   - å¯èƒ½çš„æ§åˆ¶æµç»“æ„
   - æ¨¡å—é—´è°ƒç”¨å…³ç³»
   - æ½œåœ¨çš„çƒ­ç‚¹ä»£ç 

4. **åº“è¯†åˆ«**:
   - ä»æ–‡ä»¶åæ¨æµ‹ä½¿ç”¨çš„ç¬¬ä¸‰æ–¹åº“
   - å¸¸è§æ¡†æ¶è¯†åˆ«ï¼ˆå¦‚Retrofitã€OkHttpã€Gsonç­‰ï¼‰
   - Nativeåº“çš„å¯èƒ½ç”¨é€”

5. **å¤æ‚åº¦è¯„ä¼°**:
   - ä»£ç è§„æ¨¡è¯„ä¼°
   - ç»´æŠ¤å¤æ‚åº¦
   - æ½œåœ¨çš„ä»£ç è´¨é‡é—®é¢˜
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›è¯¦ç»†çš„é™æ€åˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps(self.apk_info, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def analyze_obfuscation_hardening(self) -> Dict[str, Any]:
        """åˆ†æ3: æ··æ·†ä¸åŠ å›º"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 3: æ··æ·†ä¸åŠ å›ºåˆ†æ")
        print("="*80)
       
        team = AITeam(3, "ä»£ç æ··æ·†ä¸åŠ å›ºåˆ†æä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·åˆ†æAPKå¯èƒ½é‡‡ç”¨çš„æ··æ·†ä¸åŠ å›ºæŠ€æœ¯:

ã€åŸºç¡€ä¿¡æ¯ã€‘
- åŒ…å: {self.apk_info['manifest'].get('package_name', 'æœªçŸ¥')}
- DEXæ–‡ä»¶æ•°: {self.apk_info['dex']['count']}
- Nativeåº“: {len(self.apk_info['native']['libraries'])} ä¸ª
- ç­¾åæ–¹æ¡ˆ: {', '.join(self.apk_info['signature']['signature_versions'])}

ã€æ–‡ä»¶ç»“æ„ç‰¹å¾ã€‘
- å¤šDEX: {'æ˜¯' if self.apk_info['dex']['count'] > 1 else 'å¦'}
- Nativeä»£ç å æ¯”: {round(self.apk_info['native']['total_size'] / self.apk_info['structure']['total_size'] * 100, 2)}%

è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æå¯èƒ½çš„æ··æ·†ä¸åŠ å›ºæŠ€æœ¯:

1. **ä»£ç æ··æ·†æŒ‡æ ‡**:
   - ProGuard/R8æ··æ·†å¯èƒ½æ€§
   - æ ‡è¯†ç¬¦é‡å‘½åç¨‹åº¦æ¨æµ‹
   - å­—ç¬¦ä¸²åŠ å¯†å¯èƒ½æ€§
   - æ§åˆ¶æµæ··æ·†è¿¹è±¡

2. **åŠ å›ºæŠ€æœ¯æ¨æµ‹**:
   - DEXåŠ å£³å¯èƒ½æ€§
   - åŠ¨æ€åŠ è½½ç‰¹å¾
   - Nativeå±‚ä¿æŠ¤
   - ç±»åŠ è½½å™¨å®šåˆ¶

3. **åè°ƒè¯•æœºåˆ¶**:
   - å¯èƒ½çš„åè°ƒè¯•æ£€æµ‹
   - å®Œæ•´æ€§æ ¡éªŒ
   - æ—¶é—´æ£€æµ‹
   - ç¯å¢ƒæ£€æµ‹

4. **ä»£ç ä¿æŠ¤ç¨‹åº¦**:
   - æ•´ä½“ä¿æŠ¤å¼ºåº¦è¯„ä¼°
   - å…³é”®ä»£ç ä¿æŠ¤ç­–ç•¥
   - å¯èƒ½çš„åŠ å›ºæ–¹æ¡ˆï¼ˆ360ã€è…¾è®¯ç­‰ï¼‰

5. **åˆ†æéš¾åº¦è¯„ä¼°**:
   - é™æ€åˆ†æéš¾åº¦
   - åŠ¨æ€åˆ†æéš¾åº¦
   - é€†å‘å·¥ç¨‹å¤æ‚åº¦
   - å»ºè®®çš„åˆ†æç­–ç•¥
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›ä¸“ä¸šçš„æ··æ·†ä¸åŠ å›ºåˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps(self.apk_info, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def analyze_dynamic_behavior(self) -> Dict[str, Any]:
        """åˆ†æ4: åŠ¨æ€è¡Œä¸ºä¸è¿è¡Œæ—¶ç‰¹å¾"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 4: åŠ¨æ€è¡Œä¸ºä¸è¿è¡Œæ—¶ç‰¹å¾åˆ†æ")
        print("="*80)
       
        team = AITeam(4, "åŠ¨æ€è¡Œä¸ºåˆ†æä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·åˆ†æAPKå¯èƒ½çš„åŠ¨æ€è¡Œä¸ºå’Œè¿è¡Œæ—¶ç‰¹å¾:

ã€æƒé™åˆ†æã€‘
{chr(10).join('- ' + p for p in self.apk_info['manifest'].get('permissions', []))}

ã€Nativeåº“ä¿¡æ¯ã€‘
æ”¯æŒæ¶æ„: {', '.join(self.apk_info['native']['architectures'].keys())}
åº“åˆ—è¡¨: {', '.join([lib['name'] for lib in self.apk_info['native']['libraries']])}

ã€Assetsæ–‡ä»¶ã€‘
{chr(10).join('- ' + f for f in self.apk_info['resources']['asset_files'][:20])}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æ:

1. **è¿è¡Œæ—¶APIè°ƒç”¨é¢„æµ‹**:
   - åŸºäºæƒé™æ¨æµ‹çš„APIè°ƒç”¨
   - æ•æ„ŸAPIä½¿ç”¨ï¼ˆä½ç½®ã€ç›¸æœºã€å­˜å‚¨ç­‰ï¼‰
   - ç³»ç»ŸæœåŠ¡è®¿é—®
   - åå°„ä½¿ç”¨å¯èƒ½æ€§

2. **åŠ¨æ€ä»£ç åŠ è½½**:
   - DexClassLoaderä½¿ç”¨å¯èƒ½
   - æ’ä»¶åŒ–æ¡†æ¶è¿¹è±¡
   - çƒ­ä¿®å¤æœºåˆ¶
   - è¿œç¨‹ä»£ç æ‰§è¡Œé£é™©

3. **JNIè¾¹ç•Œåˆ†æ**:
   - Java-Nativeäº¤äº’æ¨¡å¼
   - å…³é”®é€»è¾‘åœ¨Nativeå±‚çš„å¯èƒ½æ€§
   - JNIå‡½æ•°è°ƒç”¨æ¨¡å¼
   - è·¨è¯­è¨€æ•°æ®ä¼ é€’

4. **è¿›ç¨‹ä¸çº¿ç¨‹è¡Œä¸º**:
   - å¤šè¿›ç¨‹æ¶æ„å¯èƒ½æ€§
   - åå°æœåŠ¡è¿è¡Œ
   - å¼‚æ­¥ä»»åŠ¡å¤„ç†
   - å¹¶å‘è®¿é—®æ¨¡å¼

5. **æ–‡ä»¶ä¸æ•°æ®åº“è®¿é—®**:
   - SharedPreferencesä½¿ç”¨
   - SQLiteæ•°æ®åº“
   - å¤–éƒ¨å­˜å‚¨è®¿é—®
   - å†…éƒ¨å­˜å‚¨ç­–ç•¥

6. **IPCæœºåˆ¶**:
   - Broadcastä½¿ç”¨
   - ContentProvider
   - BoundService
   - è·¨åº”ç”¨é€šä¿¡

7. **åŠ¨æ€åˆ†æå»ºè®®**:
   - Hookç‚¹æ¨è
   - ç›‘æ§é‡ç‚¹
   - Fridaè„šæœ¬æ€è·¯
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›è¯¦ç»†çš„åŠ¨æ€è¡Œä¸ºåˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps(self.apk_info, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def analyze_native_code(self) -> Dict[str, Any]:
        """åˆ†æ5: Nativeåº“ä¸æœ¬åœ°ä»£ç """
        print("\n" + "="*80)
        print("é˜¶æ®µ 5: Nativeåº“ä¸æœ¬åœ°ä»£ç åˆ†æ")
        print("="*80)
       
        team = AITeam(5, "Nativeä»£ç åˆ†æä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·æ·±å…¥åˆ†æAPKçš„Nativeåº“ä¸æœ¬åœ°ä»£ç :

ã€Nativeåº“è¯¦æƒ…ã€‘
æ”¯æŒçš„æ¶æ„: {', '.join(self.apk_info['native']['architectures'].keys())}
æ€»åº“æ•°: {len(self.apk_info['native']['libraries'])}
Nativeä»£ç æ€»å¤§å°: {round(self.apk_info['native']['total_size'] / 1024 / 1024, 2)} MB
Nativeä»£ç å æ¯”: {round(self.apk_info['native']['total_size'] / self.apk_info['structure']['total_size'] * 100, 2)}%

ã€å„æ¶æ„åº“åˆ—è¡¨ã€‘
{chr(10).join(f"{arch}: {', '.join([lib['name'] for lib in libs])}" for arch, libs in self.apk_info['native']['architectures'].items())}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æ:

1. **åº“åŠŸèƒ½æ¨æµ‹**:
   - ä»åº“åæ¨æµ‹åŠŸèƒ½ï¼ˆåŠ å¯†ã€ç½‘ç»œã€éŸ³è§†é¢‘ç­‰ï¼‰
   - ç¬¬ä¸‰æ–¹Native SDKè¯†åˆ«
   - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘åœ¨Nativeå±‚çš„å¯èƒ½æ€§
   - æ¸¸æˆå¼•æ“è¯†åˆ«ï¼ˆUnityã€Cocos2d-xã€Unrealç­‰ï¼‰

2. **æ¶æ„æ”¯æŒåˆ†æ**:
   - æ”¯æŒçš„CPUæ¶æ„åŠå…¶æ„ä¹‰
   - 32ä½vs64ä½æ”¯æŒ
   - ABIå…¼å®¹æ€§
   - æ¶æ„é€‰æ‹©ç­–ç•¥

3. **å®‰å…¨æœºåˆ¶æ¨æµ‹**:
   - å…³é”®ç®—æ³•NativeåŒ–
   - åŠ å¯†/ç­¾åéªŒè¯
   - åè°ƒè¯•æŠ€æœ¯
   - ä»£ç ä¿æŠ¤æªæ–½

4. **äºŒè¿›åˆ¶åˆ†æç­–ç•¥**:
   - IDA Proåˆ†æå»ºè®®
   - ç¬¦å·æ¢å¤éš¾åº¦
   - å…³é”®å‡½æ•°å®šä½
   - äº¤å‰å¼•ç”¨åˆ†æ

5. **JNIäº¤äº’åˆ†æ**:
   - JNI_OnLoadåˆ†æé‡ç‚¹
   - æ³¨å†Œçš„Nativeæ–¹æ³•æ¨æµ‹
   - Java-Nativeæ•°æ®äº¤æ¢
   - å›è°ƒæœºåˆ¶

6. **æ€§èƒ½ä¸ä¼˜åŒ–**:
   - Nativeä»£ç ä½¿ç”¨çš„åˆç†æ€§
   - æ€§èƒ½å…³é”®è·¯å¾„
   - å†…å­˜ç®¡ç†ç­–ç•¥
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›ä¸“ä¸šçš„Nativeä»£ç åˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps(self.apk_info, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def analyze_network_protocol(self) -> Dict[str, Any]:
        """åˆ†æ6: ç½‘ç»œä¸åè®®è¯­ä¹‰"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 6: ç½‘ç»œä¸åè®®è¯­ä¹‰åˆ†æ")
        print("="*80)
       
        team = AITeam(6, "ç½‘ç»œåè®®åˆ†æä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·åˆ†æAPKçš„ç½‘ç»œé€šä¿¡ä¸åè®®ç‰¹å¾:

ã€ç½‘ç»œæƒé™ã€‘
{chr(10).join('- ' + p for p in self.apk_info['manifest'].get('permissions', []) if 'INTERNET' in p or 'NETWORK' in p)}

ã€ç›¸å…³åº“æ¨æµ‹ã€‘
Nativeåº“: {', '.join([lib['name'] for lib in self.apk_info['native']['libraries'] if any(keyword in lib['name'].lower() for keyword in ['ssl', 'crypto', 'curl', 'http', 'net'])])}

ã€Assetsä¸­çš„é…ç½®ã€‘
{chr(10).join('- ' + f for f in self.apk_info['resources']['asset_files'] if any(ext in f.lower() for ext in ['.json', '.xml', '.conf', '.pem', '.crt']))}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æ:

1. **ç½‘ç»œé€šä¿¡æ¨¡å¼**:
   - HTTP/HTTPSä½¿ç”¨é¢„æµ‹
   - WebSocketå¯èƒ½æ€§
   - è‡ªå®šä¹‰åè®®è¿¹è±¡
   - é•¿è¿æ¥vsçŸ­è¿æ¥

2. **åŠ å¯†ä¸å®‰å…¨**:
   - SSL/TLSä½¿ç”¨
   - è¯ä¹¦å›ºå®šï¼ˆCertificate Pinningï¼‰
   - åŒå‘è®¤è¯å¯èƒ½æ€§
   - åŠ å¯†ç®—æ³•æ¨æµ‹

3. **APIé€šä¿¡æ¨¡å¼**:
   - RESTful API
   - GraphQL
   - Protocol Buffers
   - è‡ªå®šä¹‰åºåˆ—åŒ–

4. **æ•°æ®ä¼ è¾“åˆ†æ**:
   - æ˜æ–‡ä¼ è¾“é£é™©
   - æ•æ„Ÿæ•°æ®åŠ å¯†
   - æ•°æ®å‹ç¼©ç­–ç•¥
   - ä¼ è¾“ä¼˜åŒ–

5. **åç«¯æ¶æ„æ¨æµ‹**:
   - APIè®¾è®¡æ¨¡å¼
   - è®¤è¯æœºåˆ¶ï¼ˆTokenã€OAuthç­‰ï¼‰
   - ä¼šè¯ç®¡ç†
   - CDNä½¿ç”¨

6. **éšç§ä¸åˆè§„**:
   - æ•°æ®ä¸Šä¼ èŒƒå›´
   - ç”¨æˆ·è¿½è¸ª
   - ç¬¬ä¸‰æ–¹æ•°æ®å…±äº«
   - GDPR/éšç§åˆè§„

7. **æŠ“åŒ…åˆ†æå»ºè®®**:
   - æŠ“åŒ…å·¥å…·é€‰æ‹©
   - è¯ä¹¦ç»•è¿‡ç­–ç•¥
   - å…³é”®æ¥å£è¯†åˆ«
   - æµé‡é‡æ”¾æµ‹è¯•
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›è¯¦ç»†çš„ç½‘ç»œåè®®åˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps(self.apk_info, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def analyze_signature_integrity(self) -> Dict[str, Any]:
        """åˆ†æ7: ç­¾åã€å®Œæ•´æ€§ä¸æ›´æ–°æœºåˆ¶"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 7: ç­¾åã€å®Œæ•´æ€§ä¸æ›´æ–°æœºåˆ¶åˆ†æ")
        print("="*80)
       
        team = AITeam(7, "åº”ç”¨å®‰å…¨ä¸å®Œæ•´æ€§ä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·åˆ†æAPKçš„ç­¾åã€å®Œæ•´æ€§ä¿æŠ¤ä¸æ›´æ–°æœºåˆ¶:

ã€ç­¾åä¿¡æ¯ã€‘
å·²ç­¾å: {self.apk_info['signature']['signed']}
è¯ä¹¦æ–‡ä»¶: {', '.join(self.apk_info['signature']['certificates'])}
ç­¾åç‰ˆæœ¬: {', '.join(self.apk_info['signature']['signature_versions'])}

ã€åº”ç”¨ä¿¡æ¯ã€‘
åŒ…å: {self.apk_info['manifest'].get('package_name', 'æœªçŸ¥')}
ç‰ˆæœ¬å·: {self.apk_info['manifest'].get('version_code', 'æœªçŸ¥')}
ç‰ˆæœ¬å: {self.apk_info['manifest'].get('version_name', 'æœªçŸ¥')}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æ:

1. **ç­¾åç­–ç•¥åˆ†æ**:
   - ç­¾åæ–¹æ¡ˆç‰ˆæœ¬ï¼ˆv1/v2/v3/v4ï¼‰
   - ç­¾åå¼ºåº¦è¯„ä¼°
   - è¯ä¹¦é“¾åˆ†æ
   - ç­¾åè€…èº«ä»½æ¨æµ‹

2. **å®Œæ•´æ€§ä¿æŠ¤**:
   - APKç¯¡æ”¹æ£€æµ‹æœºåˆ¶
   - è‡ªæ ¡éªŒå®ç°å¯èƒ½æ€§
   - ä»£ç å®Œæ•´æ€§éªŒè¯
   - èµ„æºå®Œæ•´æ€§ä¿æŠ¤

3. **é‡æ‰“åŒ…é£é™©**:
   - é‡ç­¾åéš¾åº¦
   - ç­¾åæ ¡éªŒç»•è¿‡å¯èƒ½æ€§
   - é‡æ‰“åŒ…æ£€æµ‹æœºåˆ¶
   - é˜²äºŒæ¬¡æ‰“åŒ…æªæ–½

4. **æ›´æ–°æœºåˆ¶**:
   - åº”ç”¨å†…æ›´æ–°
   - å¢é‡æ›´æ–°å¯èƒ½æ€§
   - æ›´æ–°å®‰å…¨æ€§
   - é™çº§æ”»å‡»é˜²æŠ¤

5. **ä¸­é—´äººæ”»å‡»é˜²æŠ¤**:
   - æ›´æ–°é€šé“å®‰å…¨æ€§
   - æ›´æ–°åŒ…éªŒè¯
   - å›æ»šä¿æŠ¤
   - å¼ºåˆ¶æ›´æ–°æœºåˆ¶

6. **è¯ä¹¦ç®¡ç†**:
   - è¯ä¹¦æœ‰æ•ˆæœŸ
   - å¯†é’¥ç®¡ç†ç­–ç•¥
   - è¯ä¹¦åŠé”€æœºåˆ¶
   - åº”ç”¨è¿ç§»è€ƒè™‘

7. **å®‰å…¨å»ºè®®**:
   - ç­¾ååŠ å›ºå»ºè®®
   - å®Œæ•´æ€§ä¿æŠ¤å¢å¼º
   - æ›´æ–°æœºåˆ¶æ”¹è¿›
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›ä¸“ä¸šçš„ç­¾åä¸å®Œæ•´æ€§åˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps(self.apk_info, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def analyze_anti_analysis(self) -> Dict[str, Any]:
        """åˆ†æ8: åè°ƒè¯•ä¸ååˆ†ææœºåˆ¶"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 8: åè°ƒè¯•ä¸ååˆ†ææœºåˆ¶åˆ†æ")
        print("="*80)
       
        team = AITeam(8, "åè°ƒè¯•ä¸å¯¹æŠ—æŠ€æœ¯ä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·åˆ†æAPKå¯èƒ½é‡‡ç”¨çš„åè°ƒè¯•ä¸ååˆ†ææŠ€æœ¯:

ã€åŸºç¡€ä¿¡æ¯ã€‘
Nativeåº“æ•°: {len(self.apk_info['native']['libraries'])}
DEXæ–‡ä»¶æ•°: {self.apk_info['dex']['count']}
åŠ å›ºè¿¹è±¡: {'å¤šDEX+Nativeä»£ç ' if self.apk_info['dex']['count'] > 1 and len(self.apk_info['native']['libraries']) > 3 else 'è¾ƒå°‘'}

ã€æƒé™åˆ†æã€‘
ç³»ç»Ÿçº§æƒé™: {chr(10).join('- ' + p for p in self.apk_info['manifest'].get('permissions', []) if any(keyword in p for keyword in ['SYSTEM', 'DEBUG', 'INSTALL']))}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œæ·±å…¥åˆ†æ:

1. **åè°ƒè¯•æŠ€æœ¯**:
   - ptraceæ£€æµ‹
   - TracerPidæ£€æµ‹
   - è°ƒè¯•ç«¯å£æ£€æµ‹
   - æ—¶é—´æ£€æµ‹ï¼ˆTOCTOUï¼‰
   - æ–­ç‚¹æ£€æµ‹

2. **åæ¨¡æ‹Ÿå™¨/æ²™ç®±**:
   - æ¨¡æ‹Ÿå™¨ç‰¹å¾æ£€æµ‹
   - ç¡¬ä»¶ç‰¹å¾éªŒè¯
   - ä¼ æ„Ÿå™¨æ£€æµ‹
   - Build.FINGERPRINTæ£€æµ‹
   - ç¯å¢ƒæŒ‡çº¹è¯†åˆ«

3. **åHook/æ³¨å…¥**:
   - Fridaæ£€æµ‹
   - Xposedæ£€æµ‹
   - ç³»ç»ŸAPI Hookæ£€æµ‹
   - å†…å­˜å®Œæ•´æ€§æ£€æŸ¥
   - PLT/GOTä¿æŠ¤

4. **åé™æ€åˆ†æ**:
   - ä»£ç æ··æ·†æ·±åº¦
   - å­—ç¬¦ä¸²åŠ å¯†
   - åç¼–è¯‘å¯¹æŠ—
   - JDWPä¿æŠ¤
   - è°ƒè¯•ä¿¡æ¯æ¸…ç†

5. **å®Œæ•´æ€§æ£€æŸ¥**:
   - ç­¾åæ ¡éªŒ
   - CRC/Hashæ ¡éªŒ
   - DEXå®Œæ•´æ€§
   - SOæ–‡ä»¶æ ¡éªŒ
   - èµ„æºæ–‡ä»¶æ ¡éªŒ

6. **ç¯å¢ƒæ£€æµ‹**:
   - Rootæ£€æµ‹
   - è¶Šç‹±æ£€æµ‹
   - å±é™©åº”ç”¨æ£€æµ‹
   - VPN/ä»£ç†æ£€æµ‹
   - ç½‘ç»œç¯å¢ƒéªŒè¯

7. **å¯¹æŠ—å¼ºåº¦è¯„ä¼°**:
   - æ•´ä½“å¯¹æŠ—ç­‰çº§
   - ç»•è¿‡éš¾åº¦è¯„åˆ†
   - è–„å¼±ç¯èŠ‚è¯†åˆ«
   - ç»•è¿‡ç­–ç•¥å»ºè®®

8. **åˆ†æå·¥å…·å»ºè®®**:
   - æ¨èçš„åˆ†æå·¥å…·
   - ç»•è¿‡æŠ€æœ¯è·¯çº¿
   - è‡ªåŠ¨åŒ–åˆ†æå¯è¡Œæ€§
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›è¯¦ç»†çš„åè°ƒè¯•ä¸ååˆ†æè¯„ä¼°æŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps(self.apk_info, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def analyze_code_logic_and_modifiable_points(self) -> Dict[str, Any]:
        """åˆ†æ9: ä»£ç é€»è¾‘åˆ†æä¸å¯ä¿®æ”¹ç‚¹è¯†åˆ«"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 9: ä»£ç é€»è¾‘åˆ†æä¸å¯ä¿®æ”¹ç‚¹è¯†åˆ«")
        print("="*80)
       
        # æ‰§è¡Œä»£ç é€»è¾‘åˆ†æ
        self.code_logic_info = self.extractor.analyze_code_logic(self.decompile_info)
       
        team = AITeam(9, "ä»£ç é€»è¾‘åˆ†æä¸ä¿®æ”¹å»ºè®®ä¸“å®¶", self.models, self.base_url)
       
        task = f"""
è¯·åŸºäºåç¼–è¯‘ç»“æœåˆ†æAPKçš„ä»£ç é€»è¾‘å’Œå¯ä¿®æ”¹ç‚¹:

ã€å…¥å£ç‚¹åˆ†æã€‘
å‘ç° {len(self.code_logic_info.get('entry_points', []))} ä¸ªå…¥å£ç‚¹:
{chr(10).join(f"- {ep.get('type')}: {ep.get('name')}" for ep in self.code_logic_info.get('entry_points', [])[:20])}

ã€å…³é”®ç±»ã€‘
{chr(10).join(f"- {cls}" for cls in self.code_logic_info.get('key_classes', [])[:20])}

ã€æ•æ„Ÿæ–¹æ³•ã€‘
å‘ç° {len(self.code_logic_info.get('sensitive_methods', []))} ä¸ªæ•æ„Ÿæ–¹æ³•:
{chr(10).join(f"- {sm.get('category')}: {sm.get('keyword')} ({sm.get('file')})" for sm in self.code_logic_info.get('sensitive_methods', [])[:20])}

ã€å¯ä¿®æ”¹ç‚¹ã€‘
{chr(10).join(f"- {mp.get('point')}: {mp.get('description')}" for mp in self.code_logic_info.get('modifiable_points', []))}

ã€Hookå»ºè®®ã€‘
{chr(10).join(f"- {hs.get('target')}: {hs.get('reason')}" for hs in self.code_logic_info.get('hook_suggestions', []))}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œæ·±å…¥åˆ†æ:

1. **ä»£ç æ¶æ„åˆ†æ**:
   - åº”ç”¨çš„æ•´ä½“æ¶æ„æ¨¡å¼
   - æ¨¡å—åˆ’åˆ†å’ŒèŒè´£
   - å…³é”®ä¸šåŠ¡æµç¨‹

2. **æ•æ„Ÿæ“ä½œè¯†åˆ«**:
   - ç½‘ç»œé€šä¿¡å®ç°ç»†èŠ‚
   - æ•°æ®åŠ å¯†å’Œå­˜å‚¨æ–¹å¼
   - æƒé™ä½¿ç”¨å’Œæ•æ„ŸAPIè°ƒç”¨
   - å®‰å…¨æ£€æµ‹æœºåˆ¶

3. **å¯ä¿®æ”¹ç‚¹è¯¦ç»†åˆ†æ**:
   - æ¯ä¸ªä¿®æ”¹ç‚¹çš„å…·ä½“ä½ç½®
   - ä¿®æ”¹çš„æŠ€æœ¯æ–¹æ¡ˆ
   - ä¿®æ”¹çš„é£é™©å’Œéš¾åº¦
   - ä¿®æ”¹åçš„å½±å“èŒƒå›´

4. **Hookæ–¹æ¡ˆè®¾è®¡**:
   - Frida Hookè„šæœ¬å»ºè®®
   - Hookæ—¶æœºå’Œé¡ºåº
   - éœ€è¦Hookçš„å…·ä½“æ–¹æ³•
   - Hookå¯èƒ½é‡åˆ°çš„é—®é¢˜

5. **é€†å‘å·¥ç¨‹è·¯çº¿**:
   - åˆ†æçš„åˆ‡å…¥ç‚¹
   - å…³é”®ä»£ç å®šä½æ–¹æ³•
   - åŠ¨é™æ€ç»“åˆåˆ†æç­–ç•¥
   - è°ƒè¯•å’Œæµ‹è¯•æ–¹æ³•

6. **ä¿®æ”¹å®æ–½å»ºè®®**:
   - é‡æ‰“åŒ…æµç¨‹
   - ç­¾åå¤„ç†
   - é˜²æ£€æµ‹æªæ–½
   - æµ‹è¯•éªŒè¯æ–¹æ³•
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·æä¾›è¯¦ç»†çš„ä»£ç é€»è¾‘åˆ†æå’Œä¿®æ”¹å»ºè®®æŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, json.dumps(self.code_logic_info, ensure_ascii=False, indent=2))
        self.analysis_results.append(result)
        return result
   
    async def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print("\n" + "="*80)
        print("é˜¶æ®µ 10: ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆ")
        print("="*80)
       
        team = AITeam(10, "å®‰å…¨åˆ†ææ€»ç»“ä¸“å®¶", self.models, self.base_url)
       
        # æ±‡æ€»æ‰€æœ‰åˆ†æç»“æœ
        all_analyses = "\n\n".join([
            f"## {result['role']}\n{result['consensus']}"
            for result in self.analysis_results
        ])
       
        task = f"""
åŸºäºä»¥ä¸‹å¤šä¸ªç»´åº¦çš„æ·±å…¥åˆ†æç»“æœï¼Œè¯·ç”Ÿæˆä¸€ä»½ç»¼åˆæ€§çš„APKå®‰å…¨åˆ†ææŠ¥å‘Š:

{all_analyses}

è¯·åœ¨ç»¼åˆæŠ¥å‘Šä¸­åŒ…å«:

1. **æ‰§è¡Œæ‘˜è¦**:
   - åº”ç”¨åŸºæœ¬ä¿¡æ¯æ¦‚è¿°
   - å…³é”®å‘ç°æ€»ç»“
   - é£é™©ç­‰çº§è¯„ä¼°
   - æ ¸å¿ƒå»ºè®®

2. **æŠ€æœ¯æ¶æ„æ€»è§ˆ**:
   - æ•´ä½“æ¶æ„è¯„ä¼°
   - æŠ€æœ¯æ ˆè¯†åˆ«
   - å¼€å‘è´¨é‡è¯„ä»·

3. **å®‰å…¨æ€åŠ¿åˆ†æ**:
   - å®‰å…¨æœºåˆ¶æ€»ç»“
   - ä¸»è¦å®‰å…¨é£é™©
   - éšç§ä¿æŠ¤è¯„ä¼°
   - åˆè§„æ€§åˆ†æ

4. **ä»£ç ä¿æŠ¤è¯„ä¼°**:
   - åŠ å£³æ£€æµ‹ç»“æœ: {self.packer_info.get('packer_name', 'æ— ')}
   - æ··æ·†ç­‰çº§: {self.obfuscation_info.get('obfuscation_level', 0)}/10
   - åè°ƒè¯•èƒ½åŠ›
   - é€†å‘å·¥ç¨‹éš¾åº¦

5. **åŠ¨æ€è¡Œä¸ºç»¼è¿°**:
   - è¿è¡Œæ—¶è¡Œä¸ºæ€»ç»“
   - æ•æ„Ÿæ“ä½œæ±‡æ€»
   - æ½œåœ¨é£é™©ç‚¹

6. **ä»£ç é€»è¾‘ä¸å¯ä¿®æ”¹ç‚¹**:
   - å…¥å£ç‚¹æ•°é‡: {len(self.code_logic_info.get('entry_points', []))}
   - æ•æ„Ÿæ–¹æ³•æ•°é‡: {len(self.code_logic_info.get('sensitive_methods', []))}
   - å¯ä¿®æ”¹ç‚¹åˆ—è¡¨: {', '.join([mp.get('point', '') for mp in self.code_logic_info.get('modifiable_points', [])])}
   - Hookå»ºè®®æ•°é‡: {len(self.code_logic_info.get('hook_suggestions', []))}

7. **å»ºè®®ä¸æ”¹è¿›**:
   - å®‰å…¨åŠ å›ºå»ºè®®
   - éšç§ä¿æŠ¤æ”¹è¿›
   - åˆè§„æ€§å»ºè®®
   - æœ€ä½³å®è·µæ¨è

8. **æ¸—é€æµ‹è¯•è·¯çº¿**:
   - åˆ†æåˆ‡å…¥ç‚¹
   - æµ‹è¯•æ–¹æ³•å»ºè®®
   - å·¥å…·é€‰æ‹©æ¨è
   - é¢„æœŸæŒ‘æˆ˜

9. **è„±å£³/å»æ··æ·†å»ºè®®**:
   - è„±å£³æ–¹æ³•å’Œå·¥å…·
   - å»æ··æ·†ç­–ç•¥
   - é¢„æœŸéš¾åº¦å’Œæ—¶é—´

10. **è¯„åˆ†çŸ©é˜µ**:
   - å®‰å…¨æ€§è¯„åˆ† (1-10)
   - éšç§ä¿æŠ¤è¯„åˆ† (1-10)
   - ä»£ç è´¨é‡è¯„åˆ† (1-10)
   - é€†å‘éš¾åº¦è¯„åˆ† (1-10)
   - æ•´ä½“è¯„çº§
"""
       
        if self.requirements:
            task += f"\n\nã€åˆ†æéœ€æ±‚æ–¹å‘ã€‘\n{self.requirements}\n"
       
        task += "\nè¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šã€å…¨é¢ã€æœ‰æ·±åº¦çš„ç»¼åˆåˆ†ææŠ¥å‘Šã€‚\n"
       
        result = await team.collaborate(task, all_analyses)
        self.analysis_results.append(result)
        return result
   
    async def orchestrate(self):
        """ç¼–æ’æ•´ä¸ªåˆ†ææµç¨‹"""
        print("\n" + "ğŸ”" * 40)
        print("APKå¤šç»´åº¦å®‰å…¨åˆ†æç³»ç»Ÿå¯åŠ¨")
        print("ğŸ”" * 40)
       
        # æ­¥éª¤1: æå–APKä¿¡æ¯
        self.apk_info = self.extractor.extract_all()
       
        # æ­¥éª¤2: æ‰§è¡Œé˜¶æ®µ0 - åŠ å£³ä¸æ··æ·†æ£€æµ‹ï¼ˆå¿…é¡»åœ¨extract_allä¹‹åï¼‰
        # è¿™ä¸ªé˜¶æ®µéœ€è¦å…ˆæ‰§è¡Œï¼Œå› ä¸ºå®ƒä¼šè¿›è¡Œåç¼–è¯‘ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“åç¼–è¯‘æ˜¯å¦æˆåŠŸ
        print("\næ‰§è¡Œé˜¶æ®µ 0: åŠ å£³ä¸æ··æ·†æ£€æµ‹...")
        try:
            await self.analyze_packer_and_obfuscation()
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: åŠ å£³ä¸æ··æ·†æ£€æµ‹å¤±è´¥: {e}")
            traceback.print_exc()
       
        # æ­¥éª¤3: å®šä¹‰åç»­åˆ†æé˜¶æ®µ
        stages = [
            ("APKæ„æˆä¸å…ƒæ•°æ®", self.analyze_structure_and_metadata),
            ("é™æ€ä»£ç ç»“æ„", self.analyze_static_code_structure),
            ("æ··æ·†ä¸åŠ å›º", self.analyze_obfuscation_hardening),
            ("åŠ¨æ€è¡Œä¸º", self.analyze_dynamic_behavior),
            ("Nativeä»£ç ", self.analyze_native_code),
            ("ç½‘ç»œåè®®", self.analyze_network_protocol),
            ("ç­¾åå®Œæ•´æ€§", self.analyze_signature_integrity),
            ("åè°ƒè¯•æœºåˆ¶", self.analyze_anti_analysis),
        ]
       
        # å¦‚æœå¯ç”¨äº†åç¼–è¯‘ä¸”æˆåŠŸï¼Œæ·»åŠ ä»£ç é€»è¾‘åˆ†æé˜¶æ®µ
        if self.enable_decompile and self.decompile_info.get('success'):
            stages.append(("ä»£ç é€»è¾‘ä¸å¯ä¿®æ”¹ç‚¹", self.analyze_code_logic_and_modifiable_points))
       
        # æ·»åŠ ç»¼åˆæŠ¥å‘Šç”Ÿæˆé˜¶æ®µ
        stages.append(("ç»¼åˆæŠ¥å‘Šç”Ÿæˆ", self.generate_comprehensive_report))
       
        # æ­¥éª¤4: ä½¿ç”¨è¿›åº¦æ¡æ‰§è¡Œåç»­åˆ†æ
        total_stages = 1 + len(stages)  # 1 for stage 0 already executed
        with tqdm(total=total_stages, desc="APKåˆ†æè¿›åº¦", unit="é˜¶æ®µ", initial=1) as pbar:
            for stage_name, stage_func in stages:
                try:
                    pbar.set_description(f"æ­£åœ¨åˆ†æ: {stage_name}")
                    await stage_func()
                    pbar.update(1)
                except Exception as e:
                    print(f"\nâŒ é”™è¯¯: {stage_name} åˆ†æå¤±è´¥: {e}")
                    traceback.print_exc()
                    # ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªé˜¶æ®µ
                    pbar.update(1)
       
        # æ­¥éª¤5: ä¿å­˜ç»“æœ
        self.save_results()
       
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        self.extractor.cleanup()
       
        print("\n" + "âœ…" * 40)
        print("APKåˆ†æå®Œæˆï¼")
        print("âœ…" * 40)
   
    def save_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        apk_name = Path(self.apk_path).stem
       
        # ç¡®å®šè¾“å‡ºç›®å½•
        if self.output_dir:
            os.makedirs(self.output_dir, exist_ok=True)
            output_file = os.path.join(self.output_dir, f"apk_analysis_{apk_name}_{timestamp}.json")
            markdown_file = os.path.join(self.output_dir, f"apk_analysis_{apk_name}_{timestamp}.md")
        else:
            output_file = f"apk_analysis_{apk_name}_{timestamp}.json"
            markdown_file = f"apk_analysis_{apk_name}_{timestamp}.md"
       
        output_data = {
            "apk_info": self.apk_info,
            "packer_info": self.packer_info,
            "obfuscation_info": self.obfuscation_info,
            "decompile_info": self.decompile_info,
            "code_logic_info": self.code_logic_info,
            "analysis_results": self.analysis_results,
            "timestamp": datetime.now().isoformat(),
            "models_used": self.models
        }
       
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            print(f"\nâœ“ JSONæŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"\nâœ— ä¿å­˜JSONå¤±è´¥: {e}")
       
        # ä¿å­˜Markdownæ ¼å¼
        try:
            with open(markdown_file, 'w', encoding='utf-8') as f:
                f.write(f"# APKæ·±åº¦å®‰å…¨åˆ†ææŠ¥å‘Š\n\n")
                f.write(f"**APKæ–‡ä»¶:** {self.apk_path}\n")
                f.write(f"**åˆ†ææ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**ä½¿ç”¨æ¨¡å‹:** {', '.join(self.models)}\n\n")
               
                f.write(f"---\n\n")
                f.write(f"## åº”ç”¨åŸºæœ¬ä¿¡æ¯\n\n")
                f.write(f"- **åŒ…å:** {self.apk_info['manifest'].get('package_name', 'æœªçŸ¥')}\n")
                f.write(f"- **ç‰ˆæœ¬:** {self.apk_info['manifest'].get('version_name', 'æœªçŸ¥')} ({self.apk_info['manifest'].get('version_code', 'æœªçŸ¥')})\n")
                f.write(f"- **æœ€å°SDK:** {self.apk_info['manifest'].get('min_sdk', 'æœªçŸ¥')}\n")
                f.write(f"- **ç›®æ ‡SDK:** {self.apk_info['manifest'].get('target_sdk', 'æœªçŸ¥')}\n")
                f.write(f"- **APKå¤§å°:** {round(self.apk_info['structure']['total_size'] / 1024 / 1024, 2)} MB\n\n")
               
                # åŠ å£³æ£€æµ‹ç»“æœ
                f.write(f"## åŠ å£³æ£€æµ‹\n\n")
                f.write(f"- **æ˜¯å¦åŠ å£³:** {self.packer_info.get('is_packed', False)}\n")
                if self.packer_info.get('is_packed'):
                    f.write(f"- **åŠ å£³æ–¹æ¡ˆ:** {self.packer_info.get('packer_name', 'æœªçŸ¥')}\n")
                    f.write(f"- **ç½®ä¿¡åº¦:** {self.packer_info.get('confidence', 0)}%\n")
                    f.write(f"- **è„±å£³éš¾åº¦:** {self.packer_info.get('difficulty', 'æœªçŸ¥')}\n")
                f.write(f"\n")
               
                # æ··æ·†æ£€æµ‹ç»“æœ
                f.write(f"## æ··æ·†æ£€æµ‹\n\n")
                f.write(f"- **æ˜¯å¦æ··æ·†:** {self.obfuscation_info.get('is_obfuscated', False)}\n")
                f.write(f"- **æ··æ·†ç­‰çº§:** {self.obfuscation_info.get('obfuscation_level', 0)}/10\n")
                f.write(f"- **æ ‡è¯†ç¬¦æ··æ·†:** {self.obfuscation_info.get('identifier_obfuscation', False)}\n")
                f.write(f"- **å­—ç¬¦ä¸²åŠ å¯†:** {self.obfuscation_info.get('string_encryption', False)}\n\n")
               
                # ä»£ç é€»è¾‘åˆ†æç»“æœ
                if self.code_logic_info:
                    f.write(f"## ä»£ç é€»è¾‘åˆ†æ\n\n")
                    f.write(f"- **å…¥å£ç‚¹æ•°é‡:** {len(self.code_logic_info.get('entry_points', []))}\n")
                    f.write(f"- **å…³é”®ç±»æ•°é‡:** {len(self.code_logic_info.get('key_classes', []))}\n")
                    f.write(f"- **æ•æ„Ÿæ–¹æ³•æ•°é‡:** {len(self.code_logic_info.get('sensitive_methods', []))}\n")
                    f.write(f"- **å¯ä¿®æ”¹ç‚¹æ•°é‡:** {len(self.code_logic_info.get('modifiable_points', []))}\n")
                    f.write(f"- **Hookå»ºè®®æ•°é‡:** {len(self.code_logic_info.get('hook_suggestions', []))}\n\n")
                   
                    if self.code_logic_info.get('modifiable_points'):
                        f.write(f"### å¯ä¿®æ”¹ç‚¹åˆ—è¡¨\n\n")
                        for mp in self.code_logic_info.get('modifiable_points', []):
                            f.write(f"- **{mp.get('point')}**: {mp.get('description')} (éš¾åº¦: {mp.get('difficulty')})\n")
                        f.write(f"\n")
                   
                    if self.code_logic_info.get('hook_suggestions'):
                        f.write(f"### Hookå»ºè®®\n\n")
                        for hs in self.code_logic_info.get('hook_suggestions', []):
                            f.write(f"- **{hs.get('target')}**: {hs.get('reason')}\n")
                        f.write(f"\n")
                
                # æ•°æ®åº“åˆ†æç»“æœ
                if self.analyze_db and 'database_analysis' in self.apk_info:
                    db_analysis = self.apk_info['database_analysis']
                    f.write(f"## æ•°æ®åº“åˆ†æ\n\n")
                    f.write(f"- **æ•°æ®åº“æ–‡ä»¶æ•°é‡:** {db_analysis.get('total_databases', 0)}\n\n")
                    
                    if db_analysis.get('total_databases', 0) > 0:
                        f.write(f"### æ‰¾åˆ°çš„æ•°æ®åº“æ–‡ä»¶\n\n")
                        f.write(f"| æ–‡ä»¶å | è·¯å¾„ | å¤§å° | è¡¨æ•°é‡ | è®°å½•æ•° |\n")
                        f.write(f"|--------|------|------|--------|--------|\n")
                        
                        for db in db_analysis.get('databases', []):
                            db_name = os.path.basename(db.get('path', ''))
                            db_path = db.get('path', '')
                            # Format size
                            size_bytes = db.get('size', 0)
                            if size_bytes >= 1024 * 1024:
                                db_size = f"{size_bytes / (1024 * 1024):.2f} MB"
                            elif size_bytes >= 1024:
                                db_size = f"{size_bytes / 1024:.2f} KB"
                            else:
                                db_size = f"{size_bytes} bytes"
                            table_count = len(db.get('tables', []))
                            total_records = db.get('total_records', 0)
                            f.write(f"| {db_name} | {db_path} | {db_size} | {table_count} | {total_records} |\n")
                        
                        f.write(f"\n")
                        
                        # è¯¦ç»†åˆ†ææ¯ä¸ªæ•°æ®åº“
                        for db in db_analysis.get('databases', []):
                            db_name = os.path.basename(db.get('path', ''))
                            f.write(f"### {db_name} è¯¦ç»†åˆ†æ\n\n")
                            
                            if db.get('error'):
                                f.write(f"**é”™è¯¯:** {db.get('error')}\n\n")
                                continue
                            
                            for table in db.get('tables', []):
                                table_name = table.get('name', '')
                                f.write(f"#### è¡¨: {table_name}\n")
                                f.write(f"- åˆ—æ•°: {len(table.get('columns', []))}\n")
                                f.write(f"- è®°å½•æ•°: {table.get('row_count', 0)}\n\n")
                                
                                # è¡¨ç»“æ„
                                if table.get('columns'):
                                    # æ£€æŸ¥æ˜¯å¦æœ‰æ•æ„Ÿåˆ—
                                    sensitive_cols = [s['column'] for s in db.get('sensitive_data', []) if s['table'] == table_name]
                                    
                                    f.write(f"| åˆ—å | ç±»å‹ | æ•æ„Ÿ |\n")
                                    f.write(f"|------|------|------|\n")
                                    for col in table.get('columns', []):
                                        is_sensitive = "âš ï¸" if col['name'] in sensitive_cols else "âŒ"
                                        f.write(f"| {col['name']} | {col['type']} | {is_sensitive} |\n")
                                    f.write(f"\n")
                                
                                # æ ·æœ¬æ•°æ®ï¼ˆè„±æ•å¤„ç†ï¼‰
                                if table.get('sample_data') and len(table.get('sample_data', [])) > 0:
                                    f.write(f"##### æ ·æœ¬æ•°æ®ï¼ˆå‰5è¡Œï¼Œå·²è„±æ•ï¼‰\n\n")
                                    
                                    columns = table.get('columns', [])
                                    sample_data = table.get('sample_data', [])[:5]
                                    
                                    # è¡¨å¤´
                                    f.write(f"| {' | '.join([col['name'] for col in columns])} |\n")
                                    f.write(f"|{'|'.join(['---' for _ in columns])}|\n")
                                    
                                    # æ•°æ®è¡Œï¼ˆè„±æ•å¤„ç†ï¼‰
                                    for row in sample_data:
                                        masked_row = []
                                        for i, col in enumerate(columns):
                                            value = row[i] if i < len(row) else ''
                                            # å¯¹æ•æ„Ÿåˆ—è¿›è¡Œè„±æ•
                                            if col['name'] in sensitive_cols:
                                                masked_row.append('[REDACTED]')
                                            elif value is None:
                                                masked_row.append('NULL')
                                            elif isinstance(value, str) and len(value) > 20:
                                                masked_row.append(value[:10] + '...')
                                            else:
                                                masked_row.append(str(value))
                                        f.write(f"| {' | '.join(masked_row)} |\n")
                                    f.write(f"\n")
                            
                            # æ•æ„Ÿæ•°æ®æ±‡æ€»
                            if db.get('sensitive_data'):
                                f.write(f"#### æ•æ„Ÿæ•°æ®æ£€æµ‹\n\n")
                                f.write(f"å‘ç° {len(db.get('sensitive_data', []))} ä¸ªæ•æ„Ÿå­—æ®µ:\n\n")
                                for sensitive in db.get('sensitive_data', []):
                                    f.write(f"- **{sensitive.get('table')}.{sensitive.get('column')}** (å…³é”®è¯: {sensitive.get('keyword')})\n")
                                f.write(f"\n")
                
                f.write(f"---\n\n")
               
                for result in self.analysis_results:
                    f.write(f"## {result['role']}\n\n")
                    f.write(f"{result['consensus']}\n\n")
                    f.write(f"---\n\n")
           
            print(f"âœ“ MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {markdown_file}")
        except Exception as e:
            print(f"âœ— ä¿å­˜Markdownå¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='APKå¤šç»´åº¦å®‰å…¨åˆ†æç³»ç»Ÿ - åŸºäºå¤šæ™ºèƒ½ä½“AIåä½œ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬åˆ†æï¼ˆäº¤äº’é€‰æ‹©æ¨¡å‹ï¼‰
  python apk.py --apk app.apk

  # æŒ‡å®šæ¨¡å‹
  python apk.py --apk app.apk --model qwen2.5-coder:7b

  # å¯ç”¨åç¼–è¯‘åˆ†æ
  python apk.py --apk app.apk --model qwen2.5-coder:7b --decompile

  # å¯¼å…¥éœ€æ±‚æ–‡ä»¶
  python apk.py --apk app.apk --model qwen2.5-coder:7b --txt requirements.txt

  # å®Œæ•´åˆ†æ
  python apk.py --apk app.apk --model qwen2.5-coder:7b --decompile --txt requirements.txt --output-dir ./output

  # å¯ç”¨æ•°æ®åº“åˆ†æ
  python apk.py --apk app.apk --model qwen2.5-coder:7b --analyze-db

æ³¨æ„: éœ€è¦å®‰è£…ä»¥ä¸‹å·¥å…·ä»¥è·å¾—æ›´å®Œæ•´çš„åˆ†æç»“æœ:
  - aapt (Android Asset Packaging Tool)
  - jadx (APKåç¼–è¯‘ä¸ºJavaä»£ç ï¼Œä½¿ç”¨ --decompile æ—¶éœ€è¦)
  - apktool (APKåç¼–è¯‘ä¸ºSmaliä»£ç ï¼Œä½¿ç”¨ --decompile æ—¶éœ€è¦)
        """
    )
   
    parser.add_argument('--apk', required=True, help='APKæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model', help='æŒ‡å®šè¦ä½¿ç”¨çš„Ollamaæ¨¡å‹ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--txt', help='éœ€æ±‚æ–¹å‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--decompile', action='store_true', help='å¯ç”¨åç¼–è¯‘åˆ†æ')
    parser.add_argument('--analyze-db', action='store_true', help='å¯ç”¨æ•°æ®åº“æ·±åº¦åˆ†æ')
    parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--ollama-url', default='http://127.0.0.1:11434', help='Ollama APIåœ°å€ï¼ˆé»˜è®¤: http://127.0.0.1:11434ï¼‰')
   
    args = parser.parse_args()
   
    # æ£€æŸ¥APKæ–‡ä»¶
    if not os.path.exists(args.apk):
        print(f"âŒ é”™è¯¯: APKæ–‡ä»¶ä¸å­˜åœ¨: {args.apk}")
        sys.exit(1)
   
    # è¯»å–éœ€æ±‚æ–‡ä»¶
    requirements = ""
    if args.txt:
        if not os.path.exists(args.txt):
            print(f"âŒ é”™è¯¯: éœ€æ±‚æ–‡ä»¶ä¸å­˜åœ¨: {args.txt}")
            sys.exit(1)
        try:
            with open(args.txt, 'r', encoding='utf-8') as f:
                requirements = f.read()
            print(f"âœ“ å·²åŠ è½½éœ€æ±‚æ–‡ä»¶: {args.txt}")
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–éœ€æ±‚æ–‡ä»¶: {e}")
            sys.exit(1)
   
    # å¤„ç†æ¨¡å‹é€‰æ‹©
    model = None
    if args.model:
        # ç”¨æˆ·æŒ‡å®šäº†æ¨¡å‹ï¼ŒéªŒè¯æ¨¡å‹æ˜¯å¦å­˜åœ¨
        available_models = get_ollama_models(args.ollama_url)
        if not available_models:
            print("âš ï¸  è­¦å‘Š: æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œå°†å°è¯•ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹")
            model = args.model
        elif args.model in available_models:
            model = args.model
            print(f"âœ“ ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {model}")
        else:
            print(f"âŒ é”™è¯¯: æ¨¡å‹ '{args.model}' ä¸å­˜åœ¨")
            print(f"å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨:")
            for i, m in enumerate(available_models, 1):
                print(f"  {i}. {m}")
            sys.exit(1)
    else:
        # ç”¨æˆ·æœªæŒ‡å®šæ¨¡å‹ï¼Œæ˜¾ç¤ºåˆ—è¡¨è®©ç”¨æˆ·é€‰æ‹©
        available_models = get_ollama_models(args.ollama_url)
        if not available_models:
            print("âš ï¸  è­¦å‘Š: æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
            model = DEFAULT_MODEL
        else:
            print("\nå¯ç”¨çš„Ollamaæ¨¡å‹åˆ—è¡¨:")
            for i, m in enumerate(available_models, 1):
                print(f"  {i}. {m}")
            
            max_attempts = 5
            attempts = 0
            while attempts < max_attempts:
                try:
                    choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(available_models)}): ").strip()
                    choice_idx = int(choice) - 1
                    if 0 <= choice_idx < len(available_models):
                        model = available_models[choice_idx]
                        print(f"âœ“ å·²é€‰æ‹©æ¨¡å‹: {model}")
                        break
                    else:
                        print(f"âŒ è¯·è¾“å…¥ 1 åˆ° {len(available_models)} ä¹‹é—´çš„æ•°å­—")
                        attempts += 1
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                    attempts += 1
                except (KeyboardInterrupt, EOFError):
                    print("\n\nç”¨æˆ·å–æ¶ˆæ“ä½œ")
                    sys.exit(0)
            
            if attempts >= max_attempts:
                print(f"\nâŒ é”™è¯¯: è¶…è¿‡æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
                model = available_models[0] if available_models else DEFAULT_MODEL
                print(f"âœ“ ä½¿ç”¨æ¨¡å‹: {model}")
   
    # åˆ›å»ºåˆ†æç¼–æ’å™¨
    orchestrator = APKAnalysisOrchestrator(
        models=[model],
        apk_path=args.apk,
        requirements=requirements,
        enable_decompile=args.decompile,
        output_dir=args.output_dir,
        base_url=args.ollama_url,
        analyze_db=args.analyze_db
    )
   
    # å¼€å§‹åˆ†æ
    await orchestrator.orchestrate()


if __name__ == '__main__':
    asyncio.run(main())